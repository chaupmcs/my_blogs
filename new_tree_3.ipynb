{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "import lightgbm\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# read pickle\n",
    "with open('./data/X.pickle', 'rb') as handle:\n",
    "    X = pickle.load(handle)\n",
    "    \n",
    "with open('./data/y.pickle', 'rb') as handle:\n",
    "    y = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.364431\n",
      "[2]\ttraining's binary_logloss: 0.30797\n",
      "[3]\ttraining's binary_logloss: 0.258656\n",
      "[4]\ttraining's binary_logloss: 0.239413\n",
      "[5]\ttraining's binary_logloss: 0.213851\n",
      "[6]\ttraining's binary_logloss: 0.204589\n",
      "[7]\ttraining's binary_logloss: 0.199272\n",
      "[8]\ttraining's binary_logloss: 0.193588\n",
      "[9]\ttraining's binary_logloss: 0.18745\n",
      "[10]\ttraining's binary_logloss: 0.172793\n",
      "[11]\ttraining's binary_logloss: 0.154085\n",
      "[12]\ttraining's binary_logloss: 0.150774\n",
      "[13]\ttraining's binary_logloss: 0.130422\n",
      "[14]\ttraining's binary_logloss: 0.118352\n",
      "[15]\ttraining's binary_logloss: 0.108654\n",
      "[16]\ttraining's binary_logloss: 0.09286\n",
      "[17]\ttraining's binary_logloss: 0.0890692\n",
      "[18]\ttraining's binary_logloss: 0.0813644\n",
      "[19]\ttraining's binary_logloss: 0.0745611\n",
      "[20]\ttraining's binary_logloss: 0.0607006\n",
      "[21]\ttraining's binary_logloss: 0.0568307\n",
      "[22]\ttraining's binary_logloss: 0.0529939\n",
      "[23]\ttraining's binary_logloss: 0.0461759\n",
      "[24]\ttraining's binary_logloss: 0.0445376\n",
      "[25]\ttraining's binary_logloss: 0.0421364\n",
      "[26]\ttraining's binary_logloss: 0.0413719\n",
      "[27]\ttraining's binary_logloss: 0.0403588\n",
      "[28]\ttraining's binary_logloss: 0.0388418\n",
      "[29]\ttraining's binary_logloss: 0.0385785\n",
      "[30]\ttraining's binary_logloss: 0.0378878\n",
      "[31]\ttraining's binary_logloss: 0.0376597\n",
      "[32]\ttraining's binary_logloss: 0.0372146\n",
      "[33]\ttraining's binary_logloss: 0.0356148\n",
      "[34]\ttraining's binary_logloss: 0.0352078\n",
      "[35]\ttraining's binary_logloss: 0.0345191\n",
      "[36]\ttraining's binary_logloss: 0.0340592\n",
      "[37]\ttraining's binary_logloss: 0.0323287\n",
      "[38]\ttraining's binary_logloss: 0.031008\n",
      "[39]\ttraining's binary_logloss: 0.0308502\n",
      "[40]\ttraining's binary_logloss: 0.0307101\n",
      "[41]\ttraining's binary_logloss: 0.0306353\n",
      "[42]\ttraining's binary_logloss: 0.0301245\n",
      "[43]\ttraining's binary_logloss: 0.0297772\n",
      "[44]\ttraining's binary_logloss: 0.0290038\n",
      "[45]\ttraining's binary_logloss: 0.0284422\n",
      "[46]\ttraining's binary_logloss: 0.0282804\n",
      "[47]\ttraining's binary_logloss: 0.0280888\n",
      "[48]\ttraining's binary_logloss: 0.0279177\n",
      "[49]\ttraining's binary_logloss: 0.0278096\n",
      "[50]\ttraining's binary_logloss: 0.0274934\n",
      "[51]\ttraining's binary_logloss: 0.0271724\n",
      "[52]\ttraining's binary_logloss: 0.0270119\n",
      "[53]\ttraining's binary_logloss: 0.0268759\n",
      "[54]\ttraining's binary_logloss: 0.0268392\n",
      "[55]\ttraining's binary_logloss: 0.0268169\n",
      "[56]\ttraining's binary_logloss: 0.0266182\n",
      "[57]\ttraining's binary_logloss: 0.0264948\n",
      "[58]\ttraining's binary_logloss: 0.0263624\n",
      "[59]\ttraining's binary_logloss: 0.0262428\n",
      "[60]\ttraining's binary_logloss: 0.0262319\n",
      "[61]\ttraining's binary_logloss: 0.0262189\n",
      "[62]\ttraining's binary_logloss: 0.026185\n",
      "[63]\ttraining's binary_logloss: 0.0261446\n",
      "[64]\ttraining's binary_logloss: 0.0261288\n",
      "[65]\ttraining's binary_logloss: 0.0261131\n",
      "[66]\ttraining's binary_logloss: 0.0260995\n",
      "[67]\ttraining's binary_logloss: 0.0260822\n",
      "[68]\ttraining's binary_logloss: 0.0259353\n",
      "[69]\ttraining's binary_logloss: 0.0255589\n",
      "[70]\ttraining's binary_logloss: 0.0254019\n",
      "[71]\ttraining's binary_logloss: 0.0253824\n",
      "[72]\ttraining's binary_logloss: 0.0252899\n",
      "[73]\ttraining's binary_logloss: 0.0252332\n",
      "[74]\ttraining's binary_logloss: 0.0252174\n",
      "[75]\ttraining's binary_logloss: 0.0251745\n",
      "[76]\ttraining's binary_logloss: 0.0251688\n",
      "[77]\ttraining's binary_logloss: 0.0251668\n",
      "[78]\ttraining's binary_logloss: 0.0251379\n",
      "[79]\ttraining's binary_logloss: 0.0251352\n",
      "[80]\ttraining's binary_logloss: 0.0251315\n",
      "[81]\ttraining's binary_logloss: 0.0250722\n",
      "[82]\ttraining's binary_logloss: 0.0250701\n",
      "[83]\ttraining's binary_logloss: 0.025069\n",
      "[84]\ttraining's binary_logloss: 0.0250414\n",
      "[85]\ttraining's binary_logloss: 0.0250215\n",
      "[86]\ttraining's binary_logloss: 0.0249992\n",
      "[87]\ttraining's binary_logloss: 0.0249969\n",
      "[88]\ttraining's binary_logloss: 0.0249943\n",
      "[89]\ttraining's binary_logloss: 0.0249936\n",
      "[90]\ttraining's binary_logloss: 0.0249928\n",
      "[91]\ttraining's binary_logloss: 0.024968\n",
      "[92]\ttraining's binary_logloss: 0.0249655\n",
      "[93]\ttraining's binary_logloss: 0.0249632\n",
      "[94]\ttraining's binary_logloss: 0.0249603\n",
      "[95]\ttraining's binary_logloss: 0.0249598\n",
      "[96]\ttraining's binary_logloss: 0.0249518\n",
      "[97]\ttraining's binary_logloss: 0.0249508\n",
      "[98]\ttraining's binary_logloss: 0.0249502\n",
      "[99]\ttraining's binary_logloss: 0.0249497\n",
      "[100]\ttraining's binary_logloss: 0.0249478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9875141884222475"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth_tree =5\n",
    "num_trees=100\n",
    "\n",
    "m1 = lightgbm.LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "        importance_type='split', learning_rate=1, max_depth=max_depth_tree,\n",
    "        min_child_samples=1, min_child_weight=0, min_split_gain=0.0,\n",
    "        n_estimators=num_trees, n_jobs=-1, num_leaves=31, objective=\"binary\", \n",
    "        random_state=1, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0,  )\n",
    "m1.fit(X, y, verbose=1, eval_set = [(X,y)])\n",
    "\n",
    "res_1 = m1.predict(X)\n",
    "\n",
    "accuracy_score(res_1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_error: 0.169126\ttraining's binary_logloss: 2.6015\ttraining's _log_loss_: 0.369754\n",
      "[2]\ttraining's binary_error: 0.139614\ttraining's binary_logloss: 1.76144\ttraining's _log_loss_: 0.316638\n",
      "[3]\ttraining's binary_error: 0.103292\ttraining's binary_logloss: 2.14285\ttraining's _log_loss_: 0.282993\n",
      "[4]\ttraining's binary_error: 0.0885358\ttraining's binary_logloss: 1.26876\ttraining's _log_loss_: 0.245081\n",
      "[5]\ttraining's binary_error: 0.0851305\ttraining's binary_logloss: 1.03233\ttraining's _log_loss_: 0.228174\n",
      "[6]\ttraining's binary_error: 0.0737798\ttraining's binary_logloss: 0.673541\ttraining's _log_loss_: 0.198358\n",
      "[7]\ttraining's binary_error: 0.0658343\ttraining's binary_logloss: 0.370674\ttraining's _log_loss_: 0.182951\n",
      "[8]\ttraining's binary_error: 0.0703746\ttraining's binary_logloss: 0.328558\ttraining's _log_loss_: 0.212569\n",
      "[9]\ttraining's binary_error: 0.0590238\ttraining's binary_logloss: 0.104922\ttraining's _log_loss_: 0.173461\n",
      "[10]\ttraining's binary_error: 0.0556186\ttraining's binary_logloss: -0.253275\ttraining's _log_loss_: 0.16263\n",
      "[11]\ttraining's binary_error: 0.0522134\ttraining's binary_logloss: -0.287189\ttraining's _log_loss_: 0.143779\n",
      "[12]\ttraining's binary_error: 0.0385925\ttraining's binary_logloss: -0.475252\ttraining's _log_loss_: 0.157556\n",
      "[13]\ttraining's binary_error: 0.030647\ttraining's binary_logloss: -0.779381\ttraining's _log_loss_: 0.223125\n",
      "[14]\ttraining's binary_error: 0.0295119\ttraining's binary_logloss: -1.67595\ttraining's _log_loss_: 0.170408\n",
      "[15]\ttraining's binary_error: 0.0261067\ttraining's binary_logloss: -2.57958\ttraining's _log_loss_: 0.12769\n",
      "[16]\ttraining's binary_error: 0.0238365\ttraining's binary_logloss: -2.77287\ttraining's _log_loss_: 0.122323\n",
      "[17]\ttraining's binary_error: 0.0238365\ttraining's binary_logloss: -2.7868\ttraining's _log_loss_: 0.115546\n",
      "[18]\ttraining's binary_error: 0.0215664\ttraining's binary_logloss: -1.99989\ttraining's _log_loss_: 0.111409\n",
      "[19]\ttraining's binary_error: 0.0215664\ttraining's binary_logloss: -1.97312\ttraining's _log_loss_: 0.0712261\n",
      "[20]\ttraining's binary_error: 0.0181612\ttraining's binary_logloss: -2.12393\ttraining's _log_loss_: 0.0610898\n",
      "[21]\ttraining's binary_error: 0.015891\ttraining's binary_logloss: -2.2096\ttraining's _log_loss_: 0.0540961\n",
      "[22]\ttraining's binary_error: 0.0170261\ttraining's binary_logloss: -2.21786\ttraining's _log_loss_: 0.0529257\n",
      "[23]\ttraining's binary_error: 0.015891\ttraining's binary_logloss: -2.23736\ttraining's _log_loss_: 0.051945\n",
      "[24]\ttraining's binary_error: 0.015891\ttraining's binary_logloss: -2.2801\ttraining's _log_loss_: 0.0496963\n",
      "[25]\ttraining's binary_error: 0.015891\ttraining's binary_logloss: -2.29197\ttraining's _log_loss_: 0.0488411\n",
      "[26]\ttraining's binary_error: 0.0136209\ttraining's binary_logloss: -2.27944\ttraining's _log_loss_: 0.0457269\n",
      "[27]\ttraining's binary_error: 0.0136209\ttraining's binary_logloss: -2.30441\ttraining's _log_loss_: 0.0436101\n",
      "[28]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.35813\ttraining's _log_loss_: 0.0417082\n",
      "[29]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.34009\ttraining's _log_loss_: 0.0404987\n",
      "[30]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.37284\ttraining's _log_loss_: 0.0379308\n",
      "[31]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.39114\ttraining's _log_loss_: 0.0370292\n",
      "[32]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.39843\ttraining's _log_loss_: 0.0365575\n",
      "[33]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.40557\ttraining's _log_loss_: 0.0362232\n",
      "[34]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.42158\ttraining's _log_loss_: 0.035482\n",
      "[35]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.47084\ttraining's _log_loss_: 0.0351849\n",
      "[36]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.47926\ttraining's _log_loss_: 0.0350445\n",
      "[37]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.48453\ttraining's _log_loss_: 0.0348873\n",
      "[38]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.45245\ttraining's _log_loss_: 0.0347757\n",
      "[39]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.482\ttraining's _log_loss_: 0.0336564\n",
      "[40]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.4945\ttraining's _log_loss_: 0.0323738\n",
      "[41]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.49601\ttraining's _log_loss_: 0.0319735\n",
      "[42]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.51232\ttraining's _log_loss_: 0.0309702\n",
      "[43]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.53109\ttraining's _log_loss_: 0.0301192\n",
      "[44]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.54379\ttraining's _log_loss_: 0.0299788\n",
      "[45]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.54894\ttraining's _log_loss_: 0.0299035\n",
      "[46]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.56157\ttraining's _log_loss_: 0.0293985\n",
      "[47]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.56589\ttraining's _log_loss_: 0.0291907\n",
      "[48]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.58718\ttraining's _log_loss_: 0.0287143\n",
      "[49]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.68134\ttraining's _log_loss_: 0.02795\n",
      "[50]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.66192\ttraining's _log_loss_: 0.0278088\n",
      "[51]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.67224\ttraining's _log_loss_: 0.027598\n",
      "[52]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.68286\ttraining's _log_loss_: 0.0274128\n",
      "[53]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.68822\ttraining's _log_loss_: 0.0273861\n",
      "[54]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.69142\ttraining's _log_loss_: 0.0273176\n",
      "[55]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.70415\ttraining's _log_loss_: 0.0271184\n",
      "[56]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.70923\ttraining's _log_loss_: 0.0270265\n",
      "[57]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.72079\ttraining's _log_loss_: 0.0269996\n",
      "[58]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.76448\ttraining's _log_loss_: 0.02684\n",
      "[59]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.71096\ttraining's _log_loss_: 0.0265672\n",
      "[60]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.74014\ttraining's _log_loss_: 0.0263551\n",
      "[61]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.73343\ttraining's _log_loss_: 0.0262335\n",
      "[62]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.76268\ttraining's _log_loss_: 0.0260965\n",
      "[63]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.76668\ttraining's _log_loss_: 0.0260825\n",
      "[64]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.80994\ttraining's _log_loss_: 0.0259084\n",
      "[65]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.82372\ttraining's _log_loss_: 0.0258854\n",
      "[66]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.82943\ttraining's _log_loss_: 0.0258533\n",
      "[67]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.77632\ttraining's _log_loss_: 0.0257985\n",
      "[68]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.78735\ttraining's _log_loss_: 0.0257579\n",
      "[69]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.82217\ttraining's _log_loss_: 0.0257093\n",
      "[70]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.83253\ttraining's _log_loss_: 0.0256442\n",
      "[71]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.87382\ttraining's _log_loss_: 0.0256315\n",
      "[72]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.88014\ttraining's _log_loss_: 0.0256092\n",
      "[73]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.88539\ttraining's _log_loss_: 0.0255993\n",
      "[74]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.85885\ttraining's _log_loss_: 0.025566\n",
      "[75]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.8694\ttraining's _log_loss_: 0.0255429\n",
      "[76]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.87573\ttraining's _log_loss_: 0.0255339\n",
      "[77]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.87828\ttraining's _log_loss_: 0.0255271\n",
      "[78]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.88946\ttraining's _log_loss_: 0.0254234\n",
      "[79]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.89498\ttraining's _log_loss_: 0.0254054\n",
      "[80]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.89803\ttraining's _log_loss_: 0.0253191\n",
      "[81]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.91024\ttraining's _log_loss_: 0.0252815\n",
      "[82]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.91698\ttraining's _log_loss_: 0.0252743\n",
      "[83]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.95555\ttraining's _log_loss_: 0.0252712\n",
      "[84]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.95735\ttraining's _log_loss_: 0.0252701\n",
      "[85]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.962\ttraining's _log_loss_: 0.0252684\n",
      "[86]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.96332\ttraining's _log_loss_: 0.0252593\n",
      "[87]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.9678\ttraining's _log_loss_: 0.025255\n",
      "[88]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.94415\ttraining's _log_loss_: 0.0252409\n",
      "[89]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.94806\ttraining's _log_loss_: 0.0252349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.93096\ttraining's _log_loss_: 0.0251699\n",
      "[91]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -3.00721\ttraining's _log_loss_: 0.0251174\n",
      "[92]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.98174\ttraining's _log_loss_: 0.0251026\n",
      "[93]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.99002\ttraining's _log_loss_: 0.0250987\n",
      "[94]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -2.99274\ttraining's _log_loss_: 0.0250973\n",
      "[95]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -3.00135\ttraining's _log_loss_: 0.0250843\n",
      "[96]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -3.00689\ttraining's _log_loss_: 0.0250815\n",
      "[97]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -3.01168\ttraining's _log_loss_: 0.0250563\n",
      "[98]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -3.01389\ttraining's _log_loss_: 0.0250503\n",
      "[99]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -3.08504\ttraining's _log_loss_: 0.0250292\n",
      "[100]\ttraining's binary_error: 0.0124858\ttraining's binary_logloss: -3.08826\ttraining's _log_loss_: 0.0250279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9875141884222475"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log likelihood loss\n",
    "def log_loss_train(labels, preds): #preds here is not y_pred, it's the sum_linear_pred (raw pred, a.k.a log odd)\n",
    "    preds = 1. / (1. + np.exp(-preds)) # sigmoid convert the regression pred to probability (i.e., [0,1] range)\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1. - preds)\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "def log_loss_valid(labels, preds):\n",
    "    preds = 1. / (1. + np.exp(-preds))\n",
    "    return '_log_loss_',log_loss(labels, preds),True\n",
    "\n",
    "\n",
    "\n",
    "m_ = lightgbm.LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "        importance_type='split', learning_rate=1, max_depth=max_depth_tree,\n",
    "        min_child_samples=1, min_child_weight=0, min_split_gain=0.0,\n",
    "        n_estimators=num_trees, n_jobs=-1, num_leaves=31, objective=log_loss_train, metrics = [\"binary\", 'binary_error'],\n",
    "        random_state=1, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
    "\n",
    "# fitting model \n",
    "m_.fit(X, y, verbose=1, eval_set = [(X,y)], eval_metric=log_loss_valid)\n",
    "\n",
    "res_ = m_.predict(X)\n",
    "\n",
    "accuracy_score(res_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=1, max_depth=5,\n",
       "        metrics=['log_loss'], min_child_samples=1, min_child_weight=0,\n",
       "        min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "        objective=<function loglikelihood at 0x7f1beeb3aae8>,\n",
       "        random_state=1, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.364431\n",
      "[2]\ttraining's binary_logloss: 0.30797\n",
      "[3]\ttraining's binary_logloss: 0.258656\n",
      "[4]\ttraining's binary_logloss: 0.239413\n",
      "[5]\ttraining's binary_logloss: 0.213851\n",
      "[6]\ttraining's binary_logloss: 0.204589\n",
      "[7]\ttraining's binary_logloss: 0.199272\n",
      "[8]\ttraining's binary_logloss: 0.193588\n",
      "[9]\ttraining's binary_logloss: 0.18745\n",
      "[10]\ttraining's binary_logloss: 0.172793\n",
      "[11]\ttraining's binary_logloss: 0.154085\n",
      "[12]\ttraining's binary_logloss: 0.150774\n",
      "[13]\ttraining's binary_logloss: 0.130422\n",
      "[14]\ttraining's binary_logloss: 0.118352\n",
      "[15]\ttraining's binary_logloss: 0.108654\n",
      "[16]\ttraining's binary_logloss: 0.09286\n",
      "[17]\ttraining's binary_logloss: 0.0890692\n",
      "[18]\ttraining's binary_logloss: 0.0813644\n",
      "[19]\ttraining's binary_logloss: 0.0745611\n",
      "[20]\ttraining's binary_logloss: 0.0607006\n",
      "[21]\ttraining's binary_logloss: 0.0568307\n",
      "[22]\ttraining's binary_logloss: 0.0529939\n",
      "[23]\ttraining's binary_logloss: 0.0461759\n",
      "[24]\ttraining's binary_logloss: 0.0445376\n",
      "[25]\ttraining's binary_logloss: 0.0421364\n",
      "[26]\ttraining's binary_logloss: 0.0413719\n",
      "[27]\ttraining's binary_logloss: 0.0403588\n",
      "[28]\ttraining's binary_logloss: 0.0388418\n",
      "[29]\ttraining's binary_logloss: 0.0385785\n",
      "[30]\ttraining's binary_logloss: 0.0378878\n",
      "[31]\ttraining's binary_logloss: 0.0376597\n",
      "[32]\ttraining's binary_logloss: 0.0372146\n",
      "[33]\ttraining's binary_logloss: 0.0356148\n",
      "[34]\ttraining's binary_logloss: 0.0352078\n",
      "[35]\ttraining's binary_logloss: 0.0345191\n",
      "[36]\ttraining's binary_logloss: 0.0340592\n",
      "[37]\ttraining's binary_logloss: 0.0323287\n",
      "[38]\ttraining's binary_logloss: 0.031008\n",
      "[39]\ttraining's binary_logloss: 0.0308502\n",
      "[40]\ttraining's binary_logloss: 0.0307101\n",
      "[41]\ttraining's binary_logloss: 0.0306353\n",
      "[42]\ttraining's binary_logloss: 0.0301245\n",
      "[43]\ttraining's binary_logloss: 0.0297772\n",
      "[44]\ttraining's binary_logloss: 0.0290038\n",
      "[45]\ttraining's binary_logloss: 0.0284422\n",
      "[46]\ttraining's binary_logloss: 0.0282804\n",
      "[47]\ttraining's binary_logloss: 0.0280888\n",
      "[48]\ttraining's binary_logloss: 0.0279177\n",
      "[49]\ttraining's binary_logloss: 0.0278096\n",
      "[50]\ttraining's binary_logloss: 0.0274934\n",
      "[51]\ttraining's binary_logloss: 0.0271724\n",
      "[52]\ttraining's binary_logloss: 0.0270119\n",
      "[53]\ttraining's binary_logloss: 0.0268759\n",
      "[54]\ttraining's binary_logloss: 0.0268392\n",
      "[55]\ttraining's binary_logloss: 0.0268169\n",
      "[56]\ttraining's binary_logloss: 0.0266182\n",
      "[57]\ttraining's binary_logloss: 0.0264948\n",
      "[58]\ttraining's binary_logloss: 0.0263624\n",
      "[59]\ttraining's binary_logloss: 0.0262428\n",
      "[60]\ttraining's binary_logloss: 0.0262319\n",
      "[61]\ttraining's binary_logloss: 0.0262189\n",
      "[62]\ttraining's binary_logloss: 0.026185\n",
      "[63]\ttraining's binary_logloss: 0.0261446\n",
      "[64]\ttraining's binary_logloss: 0.0261288\n",
      "[65]\ttraining's binary_logloss: 0.0261131\n",
      "[66]\ttraining's binary_logloss: 0.0260995\n",
      "[67]\ttraining's binary_logloss: 0.0260822\n",
      "[68]\ttraining's binary_logloss: 0.0259353\n",
      "[69]\ttraining's binary_logloss: 0.0255589\n",
      "[70]\ttraining's binary_logloss: 0.0254019\n",
      "[71]\ttraining's binary_logloss: 0.0253824\n",
      "[72]\ttraining's binary_logloss: 0.0252899\n",
      "[73]\ttraining's binary_logloss: 0.0252332\n",
      "[74]\ttraining's binary_logloss: 0.0252174\n",
      "[75]\ttraining's binary_logloss: 0.0251745\n",
      "[76]\ttraining's binary_logloss: 0.0251688\n",
      "[77]\ttraining's binary_logloss: 0.0251668\n",
      "[78]\ttraining's binary_logloss: 0.0251379\n",
      "[79]\ttraining's binary_logloss: 0.0251352\n",
      "[80]\ttraining's binary_logloss: 0.0251315\n",
      "[81]\ttraining's binary_logloss: 0.0250722\n",
      "[82]\ttraining's binary_logloss: 0.0250701\n",
      "[83]\ttraining's binary_logloss: 0.025069\n",
      "[84]\ttraining's binary_logloss: 0.0250414\n",
      "[85]\ttraining's binary_logloss: 0.0250215\n",
      "[86]\ttraining's binary_logloss: 0.0249992\n",
      "[87]\ttraining's binary_logloss: 0.0249969\n",
      "[88]\ttraining's binary_logloss: 0.0249943\n",
      "[89]\ttraining's binary_logloss: 0.0249936\n",
      "[90]\ttraining's binary_logloss: 0.0249928\n",
      "[91]\ttraining's binary_logloss: 0.024968\n",
      "[92]\ttraining's binary_logloss: 0.0249655\n",
      "[93]\ttraining's binary_logloss: 0.0249632\n",
      "[94]\ttraining's binary_logloss: 0.0249603\n",
      "[95]\ttraining's binary_logloss: 0.0249598\n",
      "[96]\ttraining's binary_logloss: 0.0249518\n",
      "[97]\ttraining's binary_logloss: 0.0249508\n",
      "[98]\ttraining's binary_logloss: 0.0249502\n",
      "[99]\ttraining's binary_logloss: 0.0249497\n",
      "[100]\ttraining's binary_logloss: 0.0249478\n",
      "[101]\ttraining's binary_logloss: 0.0249454\n",
      "[102]\ttraining's binary_logloss: 0.0249452\n",
      "[103]\ttraining's binary_logloss: 0.0249414\n",
      "[104]\ttraining's binary_logloss: 0.0249401\n",
      "[105]\ttraining's binary_logloss: 0.0249394\n",
      "[106]\ttraining's binary_logloss: 0.0249388\n",
      "[107]\ttraining's binary_logloss: 0.0249385\n",
      "[108]\ttraining's binary_logloss: 0.0249383\n",
      "[109]\ttraining's binary_logloss: 0.0249248\n",
      "[110]\ttraining's binary_logloss: 0.0249011\n",
      "[111]\ttraining's binary_logloss: 0.0248915\n",
      "[112]\ttraining's binary_logloss: 0.0248838\n",
      "[113]\ttraining's binary_logloss: 0.0248834\n",
      "[114]\ttraining's binary_logloss: 0.0248784\n",
      "[115]\ttraining's binary_logloss: 0.0248782\n",
      "[116]\ttraining's binary_logloss: 0.0248782\n",
      "[117]\ttraining's binary_logloss: 0.0248753\n",
      "[118]\ttraining's binary_logloss: 0.0248752\n",
      "[119]\ttraining's binary_logloss: 0.0248751\n",
      "[120]\ttraining's binary_logloss: 0.024875\n",
      "[121]\ttraining's binary_logloss: 0.0248749\n",
      "[122]\ttraining's binary_logloss: 0.0248644\n",
      "[123]\ttraining's binary_logloss: 0.0248644\n",
      "[124]\ttraining's binary_logloss: 0.0248643\n",
      "[125]\ttraining's binary_logloss: 0.0248643\n",
      "[126]\ttraining's binary_logloss: 0.0248574\n",
      "[127]\ttraining's binary_logloss: 0.0248571\n",
      "[128]\ttraining's binary_logloss: 0.0248505\n",
      "[129]\ttraining's binary_logloss: 0.0248504\n",
      "[130]\ttraining's binary_logloss: 0.0248478\n",
      "[131]\ttraining's binary_logloss: 0.0248454\n",
      "[132]\ttraining's binary_logloss: 0.0248416\n",
      "[133]\ttraining's binary_logloss: 0.0248407\n",
      "[134]\ttraining's binary_logloss: 0.0248365\n",
      "[135]\ttraining's binary_logloss: 0.0248364\n",
      "[136]\ttraining's binary_logloss: 0.0248338\n",
      "[137]\ttraining's binary_logloss: 0.0248317\n",
      "[138]\ttraining's binary_logloss: 0.0248314\n",
      "[139]\ttraining's binary_logloss: 0.0248314\n",
      "[140]\ttraining's binary_logloss: 0.0248287\n",
      "[141]\ttraining's binary_logloss: 0.0248285\n",
      "[142]\ttraining's binary_logloss: 0.0248282\n",
      "[143]\ttraining's binary_logloss: 0.0248257\n",
      "[144]\ttraining's binary_logloss: 0.0248227\n",
      "[145]\ttraining's binary_logloss: 0.0248204\n",
      "[146]\ttraining's binary_logloss: 0.0248196\n",
      "[147]\ttraining's binary_logloss: 0.0248191\n",
      "[148]\ttraining's binary_logloss: 0.0248182\n",
      "[149]\ttraining's binary_logloss: 0.0248181\n",
      "[150]\ttraining's binary_logloss: 0.0248172\n",
      "[151]\ttraining's binary_logloss: 0.0248171\n",
      "[152]\ttraining's binary_logloss: 0.0248171\n",
      "[153]\ttraining's binary_logloss: 0.0248171\n",
      "[154]\ttraining's binary_logloss: 0.024817\n",
      "[155]\ttraining's binary_logloss: 0.0248169\n",
      "[156]\ttraining's binary_logloss: 0.0248169\n",
      "[157]\ttraining's binary_logloss: 0.0248167\n",
      "[158]\ttraining's binary_logloss: 0.024816\n",
      "[159]\ttraining's binary_logloss: 0.0248159\n",
      "[160]\ttraining's binary_logloss: 0.0248157\n",
      "[161]\ttraining's binary_logloss: 0.0248156\n",
      "[162]\ttraining's binary_logloss: 0.0248156\n",
      "[163]\ttraining's binary_logloss: 0.0248144\n",
      "[164]\ttraining's binary_logloss: 0.0248144\n",
      "[165]\ttraining's binary_logloss: 0.0248144\n",
      "[166]\ttraining's binary_logloss: 0.0248142\n",
      "[167]\ttraining's binary_logloss: 0.0248136\n",
      "[168]\ttraining's binary_logloss: 0.0248136\n",
      "[169]\ttraining's binary_logloss: 0.0248135\n",
      "[170]\ttraining's binary_logloss: 0.0248123\n",
      "[171]\ttraining's binary_logloss: 0.0248122\n",
      "[172]\ttraining's binary_logloss: 0.0248121\n",
      "[173]\ttraining's binary_logloss: 0.0248121\n",
      "[174]\ttraining's binary_logloss: 0.024812\n",
      "[175]\ttraining's binary_logloss: 0.0248119\n",
      "[176]\ttraining's binary_logloss: 0.0248119\n",
      "[177]\ttraining's binary_logloss: 0.0248117\n",
      "[178]\ttraining's binary_logloss: 0.0248117\n",
      "[179]\ttraining's binary_logloss: 0.0248113\n",
      "[180]\ttraining's binary_logloss: 0.0248113\n",
      "[181]\ttraining's binary_logloss: 0.0248113\n",
      "[182]\ttraining's binary_logloss: 0.0248113\n",
      "[183]\ttraining's binary_logloss: 0.0248113\n",
      "[184]\ttraining's binary_logloss: 0.0248112\n",
      "[185]\ttraining's binary_logloss: 0.0248107\n",
      "[186]\ttraining's binary_logloss: 0.0248107\n",
      "[187]\ttraining's binary_logloss: 0.0248106\n",
      "[188]\ttraining's binary_logloss: 0.0248106\n",
      "[189]\ttraining's binary_logloss: 0.0248106\n",
      "[190]\ttraining's binary_logloss: 0.0248105\n",
      "[191]\ttraining's binary_logloss: 0.0248104\n",
      "[192]\ttraining's binary_logloss: 0.0248104\n",
      "[193]\ttraining's binary_logloss: 0.0248103\n",
      "[194]\ttraining's binary_logloss: 0.0248103\n",
      "[195]\ttraining's binary_logloss: 0.0248103\n",
      "[196]\ttraining's binary_logloss: 0.0248103\n",
      "[197]\ttraining's binary_logloss: 0.0248103\n",
      "[198]\ttraining's binary_logloss: 0.0248103\n",
      "[199]\ttraining's binary_logloss: 0.0248102\n",
      "[200]\ttraining's binary_logloss: 0.0248101\n",
      "[201]\ttraining's binary_logloss: 0.0248101\n",
      "[202]\ttraining's binary_logloss: 0.0248101\n",
      "[203]\ttraining's binary_logloss: 0.02481\n",
      "[204]\ttraining's binary_logloss: 0.0248099\n",
      "[205]\ttraining's binary_logloss: 0.0248099\n",
      "[206]\ttraining's binary_logloss: 0.0248099\n",
      "[207]\ttraining's binary_logloss: 0.0248099\n",
      "[208]\ttraining's binary_logloss: 0.0248097\n",
      "[209]\ttraining's binary_logloss: 0.0248097\n",
      "[210]\ttraining's binary_logloss: 0.0248097\n",
      "[211]\ttraining's binary_logloss: 0.0248097\n",
      "[212]\ttraining's binary_logloss: 0.0248097\n",
      "[213]\ttraining's binary_logloss: 0.0248097\n",
      "[214]\ttraining's binary_logloss: 0.0248097\n",
      "[215]\ttraining's binary_logloss: 0.0248096\n",
      "[216]\ttraining's binary_logloss: 0.0248096\n",
      "[217]\ttraining's binary_logloss: 0.0248096\n",
      "[218]\ttraining's binary_logloss: 0.0248096\n",
      "[219]\ttraining's binary_logloss: 0.0248096\n",
      "[220]\ttraining's binary_logloss: 0.0248096\n",
      "[221]\ttraining's binary_logloss: 0.0248096\n",
      "[222]\ttraining's binary_logloss: 0.0248096\n",
      "[223]\ttraining's binary_logloss: 0.0248096\n",
      "[224]\ttraining's binary_logloss: 0.0248095\n",
      "[225]\ttraining's binary_logloss: 0.0248095\n",
      "[226]\ttraining's binary_logloss: 0.0248094\n",
      "[227]\ttraining's binary_logloss: 0.0248094\n",
      "[228]\ttraining's binary_logloss: 0.0248094\n",
      "[229]\ttraining's binary_logloss: 0.0248094\n",
      "[230]\ttraining's binary_logloss: 0.0248094\n",
      "[231]\ttraining's binary_logloss: 0.0248094\n",
      "[232]\ttraining's binary_logloss: 0.0248094\n",
      "[233]\ttraining's binary_logloss: 0.0248094\n",
      "[234]\ttraining's binary_logloss: 0.0248094\n",
      "[235]\ttraining's binary_logloss: 0.0248094\n",
      "[236]\ttraining's binary_logloss: 0.0248094\n",
      "[237]\ttraining's binary_logloss: 0.0248094\n",
      "[238]\ttraining's binary_logloss: 0.0248093\n",
      "[239]\ttraining's binary_logloss: 0.0248093\n",
      "[240]\ttraining's binary_logloss: 0.0248093\n",
      "[241]\ttraining's binary_logloss: 0.0248093\n",
      "[242]\ttraining's binary_logloss: 0.0248093\n",
      "[243]\ttraining's binary_logloss: 0.0248093\n",
      "[244]\ttraining's binary_logloss: 0.0248093\n",
      "[245]\ttraining's binary_logloss: 0.0248093\n",
      "[246]\ttraining's binary_logloss: 0.0248093\n",
      "[247]\ttraining's binary_logloss: 0.0248093\n",
      "[248]\ttraining's binary_logloss: 0.0248093\n",
      "[249]\ttraining's binary_logloss: 0.0248093\n",
      "[250]\ttraining's binary_logloss: 0.0248093\n",
      "[251]\ttraining's binary_logloss: 0.0248093\n",
      "[252]\ttraining's binary_logloss: 0.0248093\n",
      "[253]\ttraining's binary_logloss: 0.0248093\n",
      "[254]\ttraining's binary_logloss: 0.0248093\n",
      "[255]\ttraining's binary_logloss: 0.0248093\n",
      "[256]\ttraining's binary_logloss: 0.0248093\n",
      "[257]\ttraining's binary_logloss: 0.0248093\n",
      "[258]\ttraining's binary_logloss: 0.0248093\n",
      "[259]\ttraining's binary_logloss: 0.0248093\n",
      "[260]\ttraining's binary_logloss: 0.0248093\n",
      "[261]\ttraining's binary_logloss: 0.0248093\n",
      "[262]\ttraining's binary_logloss: 0.0248093\n",
      "[263]\ttraining's binary_logloss: 0.0248093\n",
      "[264]\ttraining's binary_logloss: 0.0248093\n",
      "[265]\ttraining's binary_logloss: 0.0248093\n",
      "[266]\ttraining's binary_logloss: 0.0248093\n",
      "[267]\ttraining's binary_logloss: 0.0248093\n",
      "[268]\ttraining's binary_logloss: 0.0248093\n",
      "[269]\ttraining's binary_logloss: 0.0248093\n",
      "[270]\ttraining's binary_logloss: 0.0248093\n",
      "[271]\ttraining's binary_logloss: 0.0248092\n",
      "[272]\ttraining's binary_logloss: 0.0248092\n",
      "[273]\ttraining's binary_logloss: 0.0248092\n",
      "[274]\ttraining's binary_logloss: 0.0248092\n",
      "[275]\ttraining's binary_logloss: 0.0248092\n",
      "[276]\ttraining's binary_logloss: 0.0248092\n",
      "[277]\ttraining's binary_logloss: 0.0248092\n",
      "[278]\ttraining's binary_logloss: 0.0248092\n",
      "[279]\ttraining's binary_logloss: 0.0248092\n",
      "[280]\ttraining's binary_logloss: 0.0248092\n",
      "[281]\ttraining's binary_logloss: 0.0248092\n",
      "[282]\ttraining's binary_logloss: 0.0248092\n",
      "[283]\ttraining's binary_logloss: 0.0248092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[284]\ttraining's binary_logloss: 0.0248092\n",
      "[285]\ttraining's binary_logloss: 0.0248092\n",
      "[286]\ttraining's binary_logloss: 0.0248092\n",
      "[287]\ttraining's binary_logloss: 0.0248092\n",
      "[288]\ttraining's binary_logloss: 0.0248092\n",
      "[289]\ttraining's binary_logloss: 0.0248092\n",
      "[290]\ttraining's binary_logloss: 0.0248092\n",
      "[291]\ttraining's binary_logloss: 0.0248092\n",
      "[292]\ttraining's binary_logloss: 0.0248092\n",
      "[293]\ttraining's binary_logloss: 0.0248092\n",
      "[294]\ttraining's binary_logloss: 0.0248092\n",
      "[295]\ttraining's binary_logloss: 0.0248092\n",
      "[296]\ttraining's binary_logloss: 0.0248092\n",
      "[297]\ttraining's binary_logloss: 0.377646\n",
      "[298]\ttraining's binary_logloss: 0.534462\n",
      "[299]\ttraining's binary_logloss: 0.614099\n",
      "[300]\ttraining's binary_logloss: 2.10571\n",
      "[301]\ttraining's binary_logloss: 0.823719\n",
      "[302]\ttraining's binary_logloss: 2.96362\n",
      "[303]\ttraining's binary_logloss: 3.06715\n",
      "[304]\ttraining's binary_logloss: 3.00024\n",
      "[305]\ttraining's binary_logloss: 4.35151\n",
      "[306]\ttraining's binary_logloss: 3.14084\n",
      "[307]\ttraining's binary_logloss: 3.25884\n",
      "[308]\ttraining's binary_logloss: 3.06282\n",
      "[309]\ttraining's binary_logloss: 4.12133\n",
      "[310]\ttraining's binary_logloss: 3.10203\n",
      "[311]\ttraining's binary_logloss: 3.06282\n",
      "[312]\ttraining's binary_logloss: 3.61168\n",
      "[313]\ttraining's binary_logloss: 3.65088\n",
      "[314]\ttraining's binary_logloss: 3.02362\n",
      "[315]\ttraining's binary_logloss: 2.94521\n",
      "[316]\ttraining's binary_logloss: 3.61168\n",
      "[317]\ttraining's binary_logloss: 3.49407\n",
      "[318]\ttraining's binary_logloss: 3.14123\n",
      "[319]\ttraining's binary_logloss: 3.53327\n",
      "[320]\ttraining's binary_logloss: 3.10203\n",
      "[321]\ttraining's binary_logloss: 3.65088\n",
      "[322]\ttraining's binary_logloss: 2.98441\n",
      "[323]\ttraining's binary_logloss: 3.69009\n",
      "[324]\ttraining's binary_logloss: 2.98441\n",
      "[325]\ttraining's binary_logloss: 2.90601\n",
      "[326]\ttraining's binary_logloss: 4.23894\n",
      "[327]\ttraining's binary_logloss: 2.98441\n",
      "[328]\ttraining's binary_logloss: 3.14123\n",
      "[329]\ttraining's binary_logloss: 2.8668\n",
      "[330]\ttraining's binary_logloss: 3.57247\n",
      "[331]\ttraining's binary_logloss: 3.57247\n",
      "[332]\ttraining's binary_logloss: 2.98441\n",
      "[333]\ttraining's binary_logloss: 3.65088\n",
      "[334]\ttraining's binary_logloss: 3.06282\n",
      "[335]\ttraining's binary_logloss: 2.8668\n",
      "[336]\ttraining's binary_logloss: 3.61168\n",
      "[337]\ttraining's binary_logloss: 3.53327\n",
      "[338]\ttraining's binary_logloss: 3.21964\n",
      "[339]\ttraining's binary_logloss: 2.98441\n",
      "[340]\ttraining's binary_logloss: 3.57247\n",
      "[341]\ttraining's binary_logloss: 3.65088\n",
      "[342]\ttraining's binary_logloss: 2.98441\n",
      "[343]\ttraining's binary_logloss: 3.02362\n",
      "[344]\ttraining's binary_logloss: 3.61168\n",
      "[345]\ttraining's binary_logloss: 2.90601\n",
      "[346]\ttraining's binary_logloss: 3.61168\n",
      "[347]\ttraining's binary_logloss: 3.57247\n",
      "[348]\ttraining's binary_logloss: 3.18043\n",
      "[349]\ttraining's binary_logloss: 2.94521\n",
      "[350]\ttraining's binary_logloss: 2.98441\n",
      "[351]\ttraining's binary_logloss: 3.49407\n",
      "[352]\ttraining's binary_logloss: 2.90601\n",
      "[353]\ttraining's binary_logloss: 2.98441\n",
      "[354]\ttraining's binary_logloss: 2.8668\n",
      "[355]\ttraining's binary_logloss: 3.45486\n",
      "[356]\ttraining's binary_logloss: 2.90601\n",
      "[357]\ttraining's binary_logloss: 2.8276\n",
      "[358]\ttraining's binary_logloss: 3.69009\n",
      "[359]\ttraining's binary_logloss: 2.8276\n",
      "[360]\ttraining's binary_logloss: 2.90601\n",
      "[361]\ttraining's binary_logloss: 2.8276\n",
      "[362]\ttraining's binary_logloss: 3.53327\n",
      "[363]\ttraining's binary_logloss: 2.98441\n",
      "[364]\ttraining's binary_logloss: 2.90601\n",
      "[365]\ttraining's binary_logloss: 3.41566\n",
      "[366]\ttraining's binary_logloss: 2.90601\n",
      "[367]\ttraining's binary_logloss: 2.8276\n",
      "[368]\ttraining's binary_logloss: 3.06282\n",
      "[369]\ttraining's binary_logloss: 3.45486\n",
      "[370]\ttraining's binary_logloss: 2.90601\n",
      "[371]\ttraining's binary_logloss: 2.8276\n",
      "[372]\ttraining's binary_logloss: 2.8668\n",
      "[373]\ttraining's binary_logloss: 3.61168\n",
      "[374]\ttraining's binary_logloss: 2.90601\n",
      "[375]\ttraining's binary_logloss: 2.8276\n",
      "[376]\ttraining's binary_logloss: 3.53327\n",
      "[377]\ttraining's binary_logloss: 2.8276\n",
      "[378]\ttraining's binary_logloss: 3.06282\n",
      "[379]\ttraining's binary_logloss: 2.8276\n",
      "[380]\ttraining's binary_logloss: 3.53327\n",
      "[381]\ttraining's binary_logloss: 2.8276\n",
      "[382]\ttraining's binary_logloss: 2.90601\n",
      "[383]\ttraining's binary_logloss: 3.57247\n",
      "[384]\ttraining's binary_logloss: 2.90601\n",
      "[385]\ttraining's binary_logloss: 2.8276\n",
      "[386]\ttraining's binary_logloss: 2.90601\n",
      "[387]\ttraining's binary_logloss: 3.45486\n",
      "[388]\ttraining's binary_logloss: 3.06282\n",
      "[389]\ttraining's binary_logloss: 2.8276\n",
      "[390]\ttraining's binary_logloss: 2.8668\n",
      "[391]\ttraining's binary_logloss: 3.45486\n",
      "[392]\ttraining's binary_logloss: 2.90601\n",
      "[393]\ttraining's binary_logloss: 2.98441\n",
      "[394]\ttraining's binary_logloss: 3.53327\n",
      "[395]\ttraining's binary_logloss: 2.8276\n",
      "[396]\ttraining's binary_logloss: 2.90601\n",
      "[397]\ttraining's binary_logloss: 2.8276\n",
      "[398]\ttraining's binary_logloss: 3.69009\n",
      "[399]\ttraining's binary_logloss: 2.8276\n",
      "[400]\ttraining's binary_logloss: 2.90601\n",
      "[401]\ttraining's binary_logloss: 3.41566\n",
      "[402]\ttraining's binary_logloss: 2.90601\n",
      "[403]\ttraining's binary_logloss: 2.98441\n",
      "[404]\ttraining's binary_logloss: 2.90601\n",
      "[405]\ttraining's binary_logloss: 3.45486\n",
      "[406]\ttraining's binary_logloss: 2.90601\n",
      "[407]\ttraining's binary_logloss: 2.8276\n",
      "[408]\ttraining's binary_logloss: 3.02362\n",
      "[409]\ttraining's binary_logloss: 3.45486\n",
      "[410]\ttraining's binary_logloss: 2.90601\n",
      "[411]\ttraining's binary_logloss: 2.8276\n",
      "[412]\ttraining's binary_logloss: 3.53327\n",
      "[413]\ttraining's binary_logloss: 2.98441\n",
      "[414]\ttraining's binary_logloss: 2.90601\n",
      "[415]\ttraining's binary_logloss: 2.8276\n",
      "[416]\ttraining's binary_logloss: 3.53327\n",
      "[417]\ttraining's binary_logloss: 2.8276\n",
      "[418]\ttraining's binary_logloss: 3.06282\n",
      "[419]\ttraining's binary_logloss: 3.41566\n",
      "[420]\ttraining's binary_logloss: 2.90601\n",
      "[421]\ttraining's binary_logloss: 2.8276\n",
      "[422]\ttraining's binary_logloss: 2.90601\n",
      "[423]\ttraining's binary_logloss: 3.61168\n",
      "[424]\ttraining's binary_logloss: 2.90601\n",
      "[425]\ttraining's binary_logloss: 2.8276\n",
      "[426]\ttraining's binary_logloss: 2.8668\n",
      "[427]\ttraining's binary_logloss: 3.45486\n",
      "[428]\ttraining's binary_logloss: 3.06282\n",
      "[429]\ttraining's binary_logloss: 2.8276\n",
      "[430]\ttraining's binary_logloss: 3.53327\n",
      "[431]\ttraining's binary_logloss: 2.8276\n",
      "[432]\ttraining's binary_logloss: 2.90601\n",
      "[433]\ttraining's binary_logloss: 2.98441\n",
      "[434]\ttraining's binary_logloss: 3.53327\n",
      "[435]\ttraining's binary_logloss: 2.8276\n",
      "[436]\ttraining's binary_logloss: 2.90601\n",
      "[437]\ttraining's binary_logloss: 3.41566\n",
      "[438]\ttraining's binary_logloss: 3.06282\n",
      "[439]\ttraining's binary_logloss: 2.8276\n",
      "[440]\ttraining's binary_logloss: 2.90601\n",
      "[441]\ttraining's binary_logloss: 3.45486\n",
      "[442]\ttraining's binary_logloss: 2.90601\n",
      "[443]\ttraining's binary_logloss: 2.98441\n",
      "[444]\ttraining's binary_logloss: 2.8668\n",
      "[445]\ttraining's binary_logloss: 3.45486\n",
      "[446]\ttraining's binary_logloss: 2.90601\n",
      "[447]\ttraining's binary_logloss: 2.8276\n",
      "[448]\ttraining's binary_logloss: 3.69009\n",
      "[449]\ttraining's binary_logloss: 2.8276\n",
      "[450]\ttraining's binary_logloss: 2.90601\n",
      "[451]\ttraining's binary_logloss: 2.8276\n",
      "[452]\ttraining's binary_logloss: 3.53327\n",
      "[453]\ttraining's binary_logloss: 2.98441\n",
      "[454]\ttraining's binary_logloss: 2.90601\n",
      "[455]\ttraining's binary_logloss: 3.41566\n",
      "[456]\ttraining's binary_logloss: 2.90601\n",
      "[457]\ttraining's binary_logloss: 2.8276\n",
      "[458]\ttraining's binary_logloss: 3.06282\n",
      "[459]\ttraining's binary_logloss: 3.45486\n",
      "[460]\ttraining's binary_logloss: 2.90601\n",
      "[461]\ttraining's binary_logloss: 2.8276\n",
      "[462]\ttraining's binary_logloss: 2.8668\n",
      "[463]\ttraining's binary_logloss: 3.61168\n",
      "[464]\ttraining's binary_logloss: 2.90601\n",
      "[465]\ttraining's binary_logloss: 2.8276\n",
      "[466]\ttraining's binary_logloss: 3.53327\n",
      "[467]\ttraining's binary_logloss: 2.8276\n",
      "[468]\ttraining's binary_logloss: 3.06282\n",
      "[469]\ttraining's binary_logloss: 2.8276\n",
      "[470]\ttraining's binary_logloss: 3.53327\n",
      "[471]\ttraining's binary_logloss: 2.8276\n",
      "[472]\ttraining's binary_logloss: 2.90601\n",
      "[473]\ttraining's binary_logloss: 3.57247\n",
      "[474]\ttraining's binary_logloss: 2.90601\n",
      "[475]\ttraining's binary_logloss: 2.8276\n",
      "[476]\ttraining's binary_logloss: 2.90601\n",
      "[477]\ttraining's binary_logloss: 3.45486\n",
      "[478]\ttraining's binary_logloss: 3.06282\n",
      "[479]\ttraining's binary_logloss: 2.8276\n",
      "[480]\ttraining's binary_logloss: 2.8668\n",
      "[481]\ttraining's binary_logloss: 3.45486\n",
      "[482]\ttraining's binary_logloss: 2.90601\n",
      "[483]\ttraining's binary_logloss: 2.98441\n",
      "[484]\ttraining's binary_logloss: 3.53327\n",
      "[485]\ttraining's binary_logloss: 2.8276\n",
      "[486]\ttraining's binary_logloss: 2.90601\n",
      "[487]\ttraining's binary_logloss: 2.8276\n",
      "[488]\ttraining's binary_logloss: 3.69009\n",
      "[489]\ttraining's binary_logloss: 2.8276\n",
      "[490]\ttraining's binary_logloss: 2.90601\n",
      "[491]\ttraining's binary_logloss: 3.41566\n",
      "[492]\ttraining's binary_logloss: 2.90601\n",
      "[493]\ttraining's binary_logloss: 2.98441\n",
      "[494]\ttraining's binary_logloss: 2.90601\n",
      "[495]\ttraining's binary_logloss: 3.45486\n",
      "[496]\ttraining's binary_logloss: 2.90601\n",
      "[497]\ttraining's binary_logloss: 2.8276\n",
      "[498]\ttraining's binary_logloss: 3.02362\n",
      "[499]\ttraining's binary_logloss: 3.45486\n",
      "[500]\ttraining's binary_logloss: 2.90601\n",
      "[501]\ttraining's binary_logloss: 2.8276\n",
      "[502]\ttraining's binary_logloss: 3.53327\n",
      "[503]\ttraining's binary_logloss: 2.98441\n",
      "[504]\ttraining's binary_logloss: 2.90601\n",
      "[505]\ttraining's binary_logloss: 2.8276\n",
      "[506]\ttraining's binary_logloss: 3.53327\n",
      "[507]\ttraining's binary_logloss: 2.8276\n",
      "[508]\ttraining's binary_logloss: 3.06282\n",
      "[509]\ttraining's binary_logloss: 3.41566\n",
      "[510]\ttraining's binary_logloss: 2.90601\n",
      "[511]\ttraining's binary_logloss: 2.8276\n",
      "[512]\ttraining's binary_logloss: 2.90601\n",
      "[513]\ttraining's binary_logloss: 3.61168\n",
      "[514]\ttraining's binary_logloss: 2.90601\n",
      "[515]\ttraining's binary_logloss: 2.8276\n",
      "[516]\ttraining's binary_logloss: 2.8668\n",
      "[517]\ttraining's binary_logloss: 3.45486\n",
      "[518]\ttraining's binary_logloss: 3.06282\n",
      "[519]\ttraining's binary_logloss: 2.8276\n",
      "[520]\ttraining's binary_logloss: 3.53327\n",
      "[521]\ttraining's binary_logloss: 2.8276\n",
      "[522]\ttraining's binary_logloss: 2.90601\n",
      "[523]\ttraining's binary_logloss: 2.98441\n",
      "[524]\ttraining's binary_logloss: 3.53327\n",
      "[525]\ttraining's binary_logloss: 2.8276\n",
      "[526]\ttraining's binary_logloss: 2.90601\n",
      "[527]\ttraining's binary_logloss: 3.41566\n",
      "[528]\ttraining's binary_logloss: 3.06282\n",
      "[529]\ttraining's binary_logloss: 2.8276\n",
      "[530]\ttraining's binary_logloss: 2.90601\n",
      "[531]\ttraining's binary_logloss: 3.45486\n",
      "[532]\ttraining's binary_logloss: 2.90601\n",
      "[533]\ttraining's binary_logloss: 2.98441\n",
      "[534]\ttraining's binary_logloss: 2.8668\n",
      "[535]\ttraining's binary_logloss: 3.45486\n",
      "[536]\ttraining's binary_logloss: 2.90601\n",
      "[537]\ttraining's binary_logloss: 2.8276\n",
      "[538]\ttraining's binary_logloss: 3.69009\n",
      "[539]\ttraining's binary_logloss: 2.8276\n",
      "[540]\ttraining's binary_logloss: 2.90601\n",
      "[541]\ttraining's binary_logloss: 2.8276\n",
      "[542]\ttraining's binary_logloss: 3.53327\n",
      "[543]\ttraining's binary_logloss: 2.98441\n",
      "[544]\ttraining's binary_logloss: 2.90601\n",
      "[545]\ttraining's binary_logloss: 3.41566\n",
      "[546]\ttraining's binary_logloss: 2.90601\n",
      "[547]\ttraining's binary_logloss: 2.8276\n",
      "[548]\ttraining's binary_logloss: 3.06282\n",
      "[549]\ttraining's binary_logloss: 3.45486\n",
      "[550]\ttraining's binary_logloss: 2.90601\n",
      "[551]\ttraining's binary_logloss: 2.8276\n",
      "[552]\ttraining's binary_logloss: 2.8668\n",
      "[553]\ttraining's binary_logloss: 3.61168\n",
      "[554]\ttraining's binary_logloss: 2.90601\n",
      "[555]\ttraining's binary_logloss: 2.8276\n",
      "[556]\ttraining's binary_logloss: 3.53327\n",
      "[557]\ttraining's binary_logloss: 2.8276\n",
      "[558]\ttraining's binary_logloss: 3.06282\n",
      "[559]\ttraining's binary_logloss: 2.8276\n",
      "[560]\ttraining's binary_logloss: 3.53327\n",
      "[561]\ttraining's binary_logloss: 2.8276\n",
      "[562]\ttraining's binary_logloss: 2.90601\n",
      "[563]\ttraining's binary_logloss: 3.57247\n",
      "[564]\ttraining's binary_logloss: 2.90601\n",
      "[565]\ttraining's binary_logloss: 2.8276\n",
      "[566]\ttraining's binary_logloss: 2.90601\n",
      "[567]\ttraining's binary_logloss: 3.45486\n",
      "[568]\ttraining's binary_logloss: 3.06282\n",
      "[569]\ttraining's binary_logloss: 2.8276\n",
      "[570]\ttraining's binary_logloss: 2.8668\n",
      "[571]\ttraining's binary_logloss: 3.45486\n",
      "[572]\ttraining's binary_logloss: 2.90601\n",
      "[573]\ttraining's binary_logloss: 2.98441\n",
      "[574]\ttraining's binary_logloss: 3.53327\n",
      "[575]\ttraining's binary_logloss: 2.8276\n",
      "[576]\ttraining's binary_logloss: 2.90601\n",
      "[577]\ttraining's binary_logloss: 2.8276\n",
      "[578]\ttraining's binary_logloss: 3.69009\n",
      "[579]\ttraining's binary_logloss: 2.8276\n",
      "[580]\ttraining's binary_logloss: 2.90601\n",
      "[581]\ttraining's binary_logloss: 3.41566\n",
      "[582]\ttraining's binary_logloss: 2.90601\n",
      "[583]\ttraining's binary_logloss: 2.98441\n",
      "[584]\ttraining's binary_logloss: 2.90601\n",
      "[585]\ttraining's binary_logloss: 3.45486\n",
      "[586]\ttraining's binary_logloss: 2.90601\n",
      "[587]\ttraining's binary_logloss: 2.8276\n",
      "[588]\ttraining's binary_logloss: 3.02362\n",
      "[589]\ttraining's binary_logloss: 3.45486\n",
      "[590]\ttraining's binary_logloss: 2.90601\n",
      "[591]\ttraining's binary_logloss: 2.8276\n",
      "[592]\ttraining's binary_logloss: 3.53327\n",
      "[593]\ttraining's binary_logloss: 2.98441\n",
      "[594]\ttraining's binary_logloss: 2.90601\n",
      "[595]\ttraining's binary_logloss: 2.8276\n",
      "[596]\ttraining's binary_logloss: 3.53327\n",
      "[597]\ttraining's binary_logloss: 2.8276\n",
      "[598]\ttraining's binary_logloss: 3.06282\n",
      "[599]\ttraining's binary_logloss: 3.41566\n",
      "[600]\ttraining's binary_logloss: 2.90601\n",
      "[601]\ttraining's binary_logloss: 2.8276\n",
      "[602]\ttraining's binary_logloss: 2.90601\n",
      "[603]\ttraining's binary_logloss: 3.61168\n",
      "[604]\ttraining's binary_logloss: 2.90601\n",
      "[605]\ttraining's binary_logloss: 2.8276\n",
      "[606]\ttraining's binary_logloss: 2.8668\n",
      "[607]\ttraining's binary_logloss: 3.45486\n",
      "[608]\ttraining's binary_logloss: 3.06282\n",
      "[609]\ttraining's binary_logloss: 2.8276\n",
      "[610]\ttraining's binary_logloss: 3.53327\n",
      "[611]\ttraining's binary_logloss: 2.8276\n",
      "[612]\ttraining's binary_logloss: 2.90601\n",
      "[613]\ttraining's binary_logloss: 2.98441\n",
      "[614]\ttraining's binary_logloss: 3.53327\n",
      "[615]\ttraining's binary_logloss: 2.8276\n",
      "[616]\ttraining's binary_logloss: 2.90601\n",
      "[617]\ttraining's binary_logloss: 3.41566\n",
      "[618]\ttraining's binary_logloss: 3.06282\n",
      "[619]\ttraining's binary_logloss: 2.8276\n",
      "[620]\ttraining's binary_logloss: 2.90601\n",
      "[621]\ttraining's binary_logloss: 3.45486\n",
      "[622]\ttraining's binary_logloss: 2.90601\n",
      "[623]\ttraining's binary_logloss: 2.98441\n",
      "[624]\ttraining's binary_logloss: 2.8668\n",
      "[625]\ttraining's binary_logloss: 3.45486\n",
      "[626]\ttraining's binary_logloss: 2.90601\n",
      "[627]\ttraining's binary_logloss: 2.8276\n",
      "[628]\ttraining's binary_logloss: 3.69009\n",
      "[629]\ttraining's binary_logloss: 2.8276\n",
      "[630]\ttraining's binary_logloss: 2.90601\n",
      "[631]\ttraining's binary_logloss: 2.8276\n",
      "[632]\ttraining's binary_logloss: 3.53327\n",
      "[633]\ttraining's binary_logloss: 2.98441\n",
      "[634]\ttraining's binary_logloss: 2.90601\n",
      "[635]\ttraining's binary_logloss: 3.41566\n",
      "[636]\ttraining's binary_logloss: 2.90601\n",
      "[637]\ttraining's binary_logloss: 2.8276\n",
      "[638]\ttraining's binary_logloss: 3.06282\n",
      "[639]\ttraining's binary_logloss: 3.45486\n",
      "[640]\ttraining's binary_logloss: 2.90601\n",
      "[641]\ttraining's binary_logloss: 2.8276\n",
      "[642]\ttraining's binary_logloss: 2.8668\n",
      "[643]\ttraining's binary_logloss: 3.61168\n",
      "[644]\ttraining's binary_logloss: 2.90601\n",
      "[645]\ttraining's binary_logloss: 2.8276\n",
      "[646]\ttraining's binary_logloss: 3.53327\n",
      "[647]\ttraining's binary_logloss: 2.8276\n",
      "[648]\ttraining's binary_logloss: 3.06282\n",
      "[649]\ttraining's binary_logloss: 2.8276\n",
      "[650]\ttraining's binary_logloss: 3.53327\n",
      "[651]\ttraining's binary_logloss: 2.8276\n",
      "[652]\ttraining's binary_logloss: 2.90601\n",
      "[653]\ttraining's binary_logloss: 3.57247\n",
      "[654]\ttraining's binary_logloss: 2.90601\n",
      "[655]\ttraining's binary_logloss: 2.8276\n",
      "[656]\ttraining's binary_logloss: 2.90601\n",
      "[657]\ttraining's binary_logloss: 3.45486\n",
      "[658]\ttraining's binary_logloss: 3.06282\n",
      "[659]\ttraining's binary_logloss: 2.8276\n",
      "[660]\ttraining's binary_logloss: 2.8668\n",
      "[661]\ttraining's binary_logloss: 3.45486\n",
      "[662]\ttraining's binary_logloss: 2.90601\n",
      "[663]\ttraining's binary_logloss: 2.98441\n",
      "[664]\ttraining's binary_logloss: 3.53327\n",
      "[665]\ttraining's binary_logloss: 2.8276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[666]\ttraining's binary_logloss: 2.90601\n",
      "[667]\ttraining's binary_logloss: 2.8276\n",
      "[668]\ttraining's binary_logloss: 3.69009\n",
      "[669]\ttraining's binary_logloss: 2.8276\n",
      "[670]\ttraining's binary_logloss: 2.90601\n",
      "[671]\ttraining's binary_logloss: 3.41566\n",
      "[672]\ttraining's binary_logloss: 2.90601\n",
      "[673]\ttraining's binary_logloss: 2.98441\n",
      "[674]\ttraining's binary_logloss: 2.90601\n",
      "[675]\ttraining's binary_logloss: 3.45486\n",
      "[676]\ttraining's binary_logloss: 2.90601\n",
      "[677]\ttraining's binary_logloss: 2.8276\n",
      "[678]\ttraining's binary_logloss: 3.02362\n",
      "[679]\ttraining's binary_logloss: 3.45486\n",
      "[680]\ttraining's binary_logloss: 2.90601\n",
      "[681]\ttraining's binary_logloss: 2.8276\n",
      "[682]\ttraining's binary_logloss: 3.53327\n",
      "[683]\ttraining's binary_logloss: 2.98441\n",
      "[684]\ttraining's binary_logloss: 2.90601\n",
      "[685]\ttraining's binary_logloss: 2.8276\n",
      "[686]\ttraining's binary_logloss: 3.53327\n",
      "[687]\ttraining's binary_logloss: 2.8276\n",
      "[688]\ttraining's binary_logloss: 3.06282\n",
      "[689]\ttraining's binary_logloss: 3.41566\n",
      "[690]\ttraining's binary_logloss: 2.90601\n",
      "[691]\ttraining's binary_logloss: 2.8276\n",
      "[692]\ttraining's binary_logloss: 2.90601\n",
      "[693]\ttraining's binary_logloss: 3.61168\n",
      "[694]\ttraining's binary_logloss: 2.90601\n",
      "[695]\ttraining's binary_logloss: 2.8276\n",
      "[696]\ttraining's binary_logloss: 2.8668\n",
      "[697]\ttraining's binary_logloss: 3.45486\n",
      "[698]\ttraining's binary_logloss: 3.06282\n",
      "[699]\ttraining's binary_logloss: 2.8276\n",
      "[700]\ttraining's binary_logloss: 3.53327\n",
      "[701]\ttraining's binary_logloss: 2.8276\n",
      "[702]\ttraining's binary_logloss: 2.90601\n",
      "[703]\ttraining's binary_logloss: 2.98441\n",
      "[704]\ttraining's binary_logloss: 3.53327\n",
      "[705]\ttraining's binary_logloss: 2.8276\n",
      "[706]\ttraining's binary_logloss: 2.90601\n",
      "[707]\ttraining's binary_logloss: 3.41566\n",
      "[708]\ttraining's binary_logloss: 3.06282\n",
      "[709]\ttraining's binary_logloss: 2.8276\n",
      "[710]\ttraining's binary_logloss: 2.90601\n",
      "[711]\ttraining's binary_logloss: 3.45486\n",
      "[712]\ttraining's binary_logloss: 2.90601\n",
      "[713]\ttraining's binary_logloss: 2.98441\n",
      "[714]\ttraining's binary_logloss: 2.8668\n",
      "[715]\ttraining's binary_logloss: 3.45486\n",
      "[716]\ttraining's binary_logloss: 2.90601\n",
      "[717]\ttraining's binary_logloss: 2.8276\n",
      "[718]\ttraining's binary_logloss: 3.69009\n",
      "[719]\ttraining's binary_logloss: 2.8276\n",
      "[720]\ttraining's binary_logloss: 2.90601\n",
      "[721]\ttraining's binary_logloss: 2.8276\n",
      "[722]\ttraining's binary_logloss: 3.53327\n",
      "[723]\ttraining's binary_logloss: 2.98441\n",
      "[724]\ttraining's binary_logloss: 2.90601\n",
      "[725]\ttraining's binary_logloss: 3.41566\n",
      "[726]\ttraining's binary_logloss: 2.90601\n",
      "[727]\ttraining's binary_logloss: 2.8276\n",
      "[728]\ttraining's binary_logloss: 3.06282\n",
      "[729]\ttraining's binary_logloss: 3.45486\n",
      "[730]\ttraining's binary_logloss: 2.90601\n",
      "[731]\ttraining's binary_logloss: 2.8276\n",
      "[732]\ttraining's binary_logloss: 2.8668\n",
      "[733]\ttraining's binary_logloss: 3.61168\n",
      "[734]\ttraining's binary_logloss: 2.90601\n",
      "[735]\ttraining's binary_logloss: 2.8276\n",
      "[736]\ttraining's binary_logloss: 3.53327\n",
      "[737]\ttraining's binary_logloss: 2.8276\n",
      "[738]\ttraining's binary_logloss: 3.06282\n",
      "[739]\ttraining's binary_logloss: 2.8276\n",
      "[740]\ttraining's binary_logloss: 3.53327\n",
      "[741]\ttraining's binary_logloss: 2.8276\n",
      "[742]\ttraining's binary_logloss: 2.90601\n",
      "[743]\ttraining's binary_logloss: 3.57247\n",
      "[744]\ttraining's binary_logloss: 2.90601\n",
      "[745]\ttraining's binary_logloss: 2.8276\n",
      "[746]\ttraining's binary_logloss: 2.90601\n",
      "[747]\ttraining's binary_logloss: 3.45486\n",
      "[748]\ttraining's binary_logloss: 3.06282\n",
      "[749]\ttraining's binary_logloss: 2.8276\n",
      "[750]\ttraining's binary_logloss: 2.8668\n",
      "[751]\ttraining's binary_logloss: 3.45486\n",
      "[752]\ttraining's binary_logloss: 2.90601\n",
      "[753]\ttraining's binary_logloss: 2.98441\n",
      "[754]\ttraining's binary_logloss: 3.53327\n",
      "[755]\ttraining's binary_logloss: 2.8276\n",
      "[756]\ttraining's binary_logloss: 2.90601\n",
      "[757]\ttraining's binary_logloss: 2.8276\n",
      "[758]\ttraining's binary_logloss: 3.69009\n",
      "[759]\ttraining's binary_logloss: 2.8276\n",
      "[760]\ttraining's binary_logloss: 2.90601\n",
      "[761]\ttraining's binary_logloss: 3.41566\n",
      "[762]\ttraining's binary_logloss: 2.90601\n",
      "[763]\ttraining's binary_logloss: 2.98441\n",
      "[764]\ttraining's binary_logloss: 2.90601\n",
      "[765]\ttraining's binary_logloss: 3.45486\n",
      "[766]\ttraining's binary_logloss: 2.90601\n",
      "[767]\ttraining's binary_logloss: 2.8276\n",
      "[768]\ttraining's binary_logloss: 3.02362\n",
      "[769]\ttraining's binary_logloss: 3.45486\n",
      "[770]\ttraining's binary_logloss: 2.90601\n",
      "[771]\ttraining's binary_logloss: 2.8276\n",
      "[772]\ttraining's binary_logloss: 3.53327\n",
      "[773]\ttraining's binary_logloss: 2.98441\n",
      "[774]\ttraining's binary_logloss: 2.90601\n",
      "[775]\ttraining's binary_logloss: 2.8276\n",
      "[776]\ttraining's binary_logloss: 3.53327\n",
      "[777]\ttraining's binary_logloss: 2.8276\n",
      "[778]\ttraining's binary_logloss: 3.06282\n",
      "[779]\ttraining's binary_logloss: 3.41566\n",
      "[780]\ttraining's binary_logloss: 2.90601\n",
      "[781]\ttraining's binary_logloss: 2.8276\n",
      "[782]\ttraining's binary_logloss: 2.90601\n",
      "[783]\ttraining's binary_logloss: 3.61168\n",
      "[784]\ttraining's binary_logloss: 2.90601\n",
      "[785]\ttraining's binary_logloss: 2.8276\n",
      "[786]\ttraining's binary_logloss: 2.8668\n",
      "[787]\ttraining's binary_logloss: 3.45486\n",
      "[788]\ttraining's binary_logloss: 3.06282\n",
      "[789]\ttraining's binary_logloss: 2.8276\n",
      "[790]\ttraining's binary_logloss: 3.53327\n",
      "[791]\ttraining's binary_logloss: 2.8276\n",
      "[792]\ttraining's binary_logloss: 2.90601\n",
      "[793]\ttraining's binary_logloss: 2.98441\n",
      "[794]\ttraining's binary_logloss: 3.53327\n",
      "[795]\ttraining's binary_logloss: 2.8276\n",
      "[796]\ttraining's binary_logloss: 2.90601\n",
      "[797]\ttraining's binary_logloss: 3.41566\n",
      "[798]\ttraining's binary_logloss: 3.06282\n",
      "[799]\ttraining's binary_logloss: 2.8276\n",
      "[800]\ttraining's binary_logloss: 2.90601\n",
      "[801]\ttraining's binary_logloss: 3.45486\n",
      "[802]\ttraining's binary_logloss: 2.90601\n",
      "[803]\ttraining's binary_logloss: 2.98441\n",
      "[804]\ttraining's binary_logloss: 2.8668\n",
      "[805]\ttraining's binary_logloss: 3.45486\n",
      "[806]\ttraining's binary_logloss: 2.90601\n",
      "[807]\ttraining's binary_logloss: 2.8276\n",
      "[808]\ttraining's binary_logloss: 3.69009\n",
      "[809]\ttraining's binary_logloss: 2.8276\n",
      "[810]\ttraining's binary_logloss: 2.90601\n",
      "[811]\ttraining's binary_logloss: 2.8276\n",
      "[812]\ttraining's binary_logloss: 3.53327\n",
      "[813]\ttraining's binary_logloss: 2.98441\n",
      "[814]\ttraining's binary_logloss: 2.90601\n",
      "[815]\ttraining's binary_logloss: 3.41566\n",
      "[816]\ttraining's binary_logloss: 2.90601\n",
      "[817]\ttraining's binary_logloss: 2.8276\n",
      "[818]\ttraining's binary_logloss: 3.06282\n",
      "[819]\ttraining's binary_logloss: 3.45486\n",
      "[820]\ttraining's binary_logloss: 2.90601\n",
      "[821]\ttraining's binary_logloss: 2.8276\n",
      "[822]\ttraining's binary_logloss: 2.8668\n",
      "[823]\ttraining's binary_logloss: 3.61168\n",
      "[824]\ttraining's binary_logloss: 2.90601\n",
      "[825]\ttraining's binary_logloss: 2.8276\n",
      "[826]\ttraining's binary_logloss: 3.53327\n",
      "[827]\ttraining's binary_logloss: 2.8276\n",
      "[828]\ttraining's binary_logloss: 3.06282\n",
      "[829]\ttraining's binary_logloss: 2.8276\n",
      "[830]\ttraining's binary_logloss: 3.53327\n",
      "[831]\ttraining's binary_logloss: 2.8276\n",
      "[832]\ttraining's binary_logloss: 2.90601\n",
      "[833]\ttraining's binary_logloss: 3.57247\n",
      "[834]\ttraining's binary_logloss: 2.90601\n",
      "[835]\ttraining's binary_logloss: 2.8276\n",
      "[836]\ttraining's binary_logloss: 2.90601\n",
      "[837]\ttraining's binary_logloss: 3.45486\n",
      "[838]\ttraining's binary_logloss: 3.06282\n",
      "[839]\ttraining's binary_logloss: 2.8276\n",
      "[840]\ttraining's binary_logloss: 2.8668\n",
      "[841]\ttraining's binary_logloss: 3.45486\n",
      "[842]\ttraining's binary_logloss: 2.90601\n",
      "[843]\ttraining's binary_logloss: 2.98441\n",
      "[844]\ttraining's binary_logloss: 3.53327\n",
      "[845]\ttraining's binary_logloss: 2.8276\n",
      "[846]\ttraining's binary_logloss: 2.90601\n",
      "[847]\ttraining's binary_logloss: 2.8276\n",
      "[848]\ttraining's binary_logloss: 3.69009\n",
      "[849]\ttraining's binary_logloss: 2.8276\n",
      "[850]\ttraining's binary_logloss: 2.90601\n",
      "[851]\ttraining's binary_logloss: 3.41566\n",
      "[852]\ttraining's binary_logloss: 2.90601\n",
      "[853]\ttraining's binary_logloss: 2.98441\n",
      "[854]\ttraining's binary_logloss: 2.90601\n",
      "[855]\ttraining's binary_logloss: 3.45486\n",
      "[856]\ttraining's binary_logloss: 2.90601\n",
      "[857]\ttraining's binary_logloss: 2.8276\n",
      "[858]\ttraining's binary_logloss: 3.02362\n",
      "[859]\ttraining's binary_logloss: 3.45486\n",
      "[860]\ttraining's binary_logloss: 2.90601\n",
      "[861]\ttraining's binary_logloss: 2.8276\n",
      "[862]\ttraining's binary_logloss: 3.53327\n",
      "[863]\ttraining's binary_logloss: 2.98441\n",
      "[864]\ttraining's binary_logloss: 2.90601\n",
      "[865]\ttraining's binary_logloss: 2.8276\n",
      "[866]\ttraining's binary_logloss: 3.53327\n",
      "[867]\ttraining's binary_logloss: 2.8276\n",
      "[868]\ttraining's binary_logloss: 3.06282\n",
      "[869]\ttraining's binary_logloss: 3.41566\n",
      "[870]\ttraining's binary_logloss: 2.90601\n",
      "[871]\ttraining's binary_logloss: 2.8276\n",
      "[872]\ttraining's binary_logloss: 2.90601\n",
      "[873]\ttraining's binary_logloss: 3.61168\n",
      "[874]\ttraining's binary_logloss: 2.90601\n",
      "[875]\ttraining's binary_logloss: 2.8276\n",
      "[876]\ttraining's binary_logloss: 2.8668\n",
      "[877]\ttraining's binary_logloss: 3.45486\n",
      "[878]\ttraining's binary_logloss: 3.06282\n",
      "[879]\ttraining's binary_logloss: 2.8276\n",
      "[880]\ttraining's binary_logloss: 3.53327\n",
      "[881]\ttraining's binary_logloss: 2.8276\n",
      "[882]\ttraining's binary_logloss: 2.90601\n",
      "[883]\ttraining's binary_logloss: 2.98441\n",
      "[884]\ttraining's binary_logloss: 3.53327\n",
      "[885]\ttraining's binary_logloss: 2.8276\n",
      "[886]\ttraining's binary_logloss: 2.90601\n",
      "[887]\ttraining's binary_logloss: 3.41566\n",
      "[888]\ttraining's binary_logloss: 3.06282\n",
      "[889]\ttraining's binary_logloss: 2.8276\n",
      "[890]\ttraining's binary_logloss: 2.90601\n",
      "[891]\ttraining's binary_logloss: 3.45486\n",
      "[892]\ttraining's binary_logloss: 2.90601\n",
      "[893]\ttraining's binary_logloss: 2.98441\n",
      "[894]\ttraining's binary_logloss: 2.8668\n",
      "[895]\ttraining's binary_logloss: 3.45486\n",
      "[896]\ttraining's binary_logloss: 2.90601\n",
      "[897]\ttraining's binary_logloss: 2.8276\n",
      "[898]\ttraining's binary_logloss: 3.69009\n",
      "[899]\ttraining's binary_logloss: 2.8276\n",
      "[900]\ttraining's binary_logloss: 2.90601\n",
      "[901]\ttraining's binary_logloss: 2.8276\n",
      "[902]\ttraining's binary_logloss: 3.53327\n",
      "[903]\ttraining's binary_logloss: 2.98441\n",
      "[904]\ttraining's binary_logloss: 2.90601\n",
      "[905]\ttraining's binary_logloss: 3.41566\n",
      "[906]\ttraining's binary_logloss: 2.90601\n",
      "[907]\ttraining's binary_logloss: 2.8276\n",
      "[908]\ttraining's binary_logloss: 3.06282\n",
      "[909]\ttraining's binary_logloss: 3.45486\n",
      "[910]\ttraining's binary_logloss: 2.90601\n",
      "[911]\ttraining's binary_logloss: 2.8276\n",
      "[912]\ttraining's binary_logloss: 2.8668\n",
      "[913]\ttraining's binary_logloss: 3.61168\n",
      "[914]\ttraining's binary_logloss: 2.90601\n",
      "[915]\ttraining's binary_logloss: 2.8276\n",
      "[916]\ttraining's binary_logloss: 3.53327\n",
      "[917]\ttraining's binary_logloss: 2.8276\n",
      "[918]\ttraining's binary_logloss: 3.06282\n",
      "[919]\ttraining's binary_logloss: 2.8276\n",
      "[920]\ttraining's binary_logloss: 3.53327\n",
      "[921]\ttraining's binary_logloss: 2.8276\n",
      "[922]\ttraining's binary_logloss: 2.90601\n",
      "[923]\ttraining's binary_logloss: 3.57247\n",
      "[924]\ttraining's binary_logloss: 2.90601\n",
      "[925]\ttraining's binary_logloss: 2.8276\n",
      "[926]\ttraining's binary_logloss: 2.90601\n",
      "[927]\ttraining's binary_logloss: 3.45486\n",
      "[928]\ttraining's binary_logloss: 3.06282\n",
      "[929]\ttraining's binary_logloss: 2.8276\n",
      "[930]\ttraining's binary_logloss: 2.8668\n",
      "[931]\ttraining's binary_logloss: 3.45486\n",
      "[932]\ttraining's binary_logloss: 2.90601\n",
      "[933]\ttraining's binary_logloss: 2.98441\n",
      "[934]\ttraining's binary_logloss: 3.53327\n",
      "[935]\ttraining's binary_logloss: 2.8276\n",
      "[936]\ttraining's binary_logloss: 2.90601\n",
      "[937]\ttraining's binary_logloss: 2.8276\n",
      "[938]\ttraining's binary_logloss: 3.69009\n",
      "[939]\ttraining's binary_logloss: 2.8276\n",
      "[940]\ttraining's binary_logloss: 2.90601\n",
      "[941]\ttraining's binary_logloss: 3.41566\n",
      "[942]\ttraining's binary_logloss: 2.90601\n",
      "[943]\ttraining's binary_logloss: 2.98441\n",
      "[944]\ttraining's binary_logloss: 2.90601\n",
      "[945]\ttraining's binary_logloss: 3.45486\n",
      "[946]\ttraining's binary_logloss: 2.90601\n",
      "[947]\ttraining's binary_logloss: 2.8276\n",
      "[948]\ttraining's binary_logloss: 3.02362\n",
      "[949]\ttraining's binary_logloss: 3.45486\n",
      "[950]\ttraining's binary_logloss: 2.90601\n",
      "[951]\ttraining's binary_logloss: 2.8276\n",
      "[952]\ttraining's binary_logloss: 3.53327\n",
      "[953]\ttraining's binary_logloss: 2.98441\n",
      "[954]\ttraining's binary_logloss: 2.90601\n",
      "[955]\ttraining's binary_logloss: 2.8276\n",
      "[956]\ttraining's binary_logloss: 3.53327\n",
      "[957]\ttraining's binary_logloss: 2.8276\n",
      "[958]\ttraining's binary_logloss: 3.06282\n",
      "[959]\ttraining's binary_logloss: 3.41566\n",
      "[960]\ttraining's binary_logloss: 2.90601\n",
      "[961]\ttraining's binary_logloss: 2.8276\n",
      "[962]\ttraining's binary_logloss: 2.90601\n",
      "[963]\ttraining's binary_logloss: 3.61168\n",
      "[964]\ttraining's binary_logloss: 2.90601\n",
      "[965]\ttraining's binary_logloss: 2.8276\n",
      "[966]\ttraining's binary_logloss: 2.8668\n",
      "[967]\ttraining's binary_logloss: 3.45486\n",
      "[968]\ttraining's binary_logloss: 3.06282\n",
      "[969]\ttraining's binary_logloss: 2.8276\n",
      "[970]\ttraining's binary_logloss: 3.53327\n",
      "[971]\ttraining's binary_logloss: 2.8276\n",
      "[972]\ttraining's binary_logloss: 2.90601\n",
      "[973]\ttraining's binary_logloss: 2.98441\n",
      "[974]\ttraining's binary_logloss: 3.53327\n",
      "[975]\ttraining's binary_logloss: 2.8276\n",
      "[976]\ttraining's binary_logloss: 2.90601\n",
      "[977]\ttraining's binary_logloss: 3.41566\n",
      "[978]\ttraining's binary_logloss: 3.06282\n",
      "[979]\ttraining's binary_logloss: 2.8276\n",
      "[980]\ttraining's binary_logloss: 2.90601\n",
      "[981]\ttraining's binary_logloss: 3.45486\n",
      "[982]\ttraining's binary_logloss: 2.90601\n",
      "[983]\ttraining's binary_logloss: 2.98441\n",
      "[984]\ttraining's binary_logloss: 2.8668\n",
      "[985]\ttraining's binary_logloss: 3.45486\n",
      "[986]\ttraining's binary_logloss: 2.90601\n",
      "[987]\ttraining's binary_logloss: 2.8276\n",
      "[988]\ttraining's binary_logloss: 3.69009\n",
      "[989]\ttraining's binary_logloss: 2.8276\n",
      "[990]\ttraining's binary_logloss: 2.90601\n",
      "[991]\ttraining's binary_logloss: 2.8276\n",
      "[992]\ttraining's binary_logloss: 3.53327\n",
      "[993]\ttraining's binary_logloss: 2.98441\n",
      "[994]\ttraining's binary_logloss: 2.90601\n",
      "[995]\ttraining's binary_logloss: 3.41566\n",
      "[996]\ttraining's binary_logloss: 2.90601\n",
      "[997]\ttraining's binary_logloss: 2.8276\n",
      "[998]\ttraining's binary_logloss: 3.06282\n",
      "[999]\ttraining's binary_logloss: 3.45486\n",
      "[1000]\ttraining's binary_logloss: 2.90601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8910329171396141"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth_tree =5\n",
    "num_trees=1000\n",
    "\n",
    "m2 = lightgbm.LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "        importance_type='split', learning_rate=1, max_depth=max_depth_tree,\n",
    "        min_child_samples=1, min_child_weight=0, min_split_gain=0.0,\n",
    "        n_estimators=num_trees, n_jobs=-1, num_leaves=31, objective=\"binary\", \n",
    "        random_state=1, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
    "m2.fit(X, y, verbose=1, eval_set = [(X,y)])\n",
    "\n",
    "res_2 = m2.predict(X)\n",
    "\n",
    "accuracy_score(res_2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 2.6015\ttraining's log_loss_: 0.369754\ttraining's accuracy: 0.830874\n",
      "[2]\ttraining's binary_logloss: 1.76144\ttraining's log_loss_: 0.316638\ttraining's accuracy: 0.860386\n",
      "[3]\ttraining's binary_logloss: 2.14285\ttraining's log_loss_: 0.282993\ttraining's accuracy: 0.896708\n",
      "[4]\ttraining's binary_logloss: 1.26876\ttraining's log_loss_: 0.245081\ttraining's accuracy: 0.911464\n",
      "[5]\ttraining's binary_logloss: 1.03233\ttraining's log_loss_: 0.228174\ttraining's accuracy: 0.914869\n",
      "[6]\ttraining's binary_logloss: 0.673541\ttraining's log_loss_: 0.198358\ttraining's accuracy: 0.92622\n",
      "[7]\ttraining's binary_logloss: 0.371114\ttraining's log_loss_: 0.182951\ttraining's accuracy: 0.934166\n",
      "[8]\ttraining's binary_logloss: 0.329367\ttraining's log_loss_: 0.212572\ttraining's accuracy: 0.929625\n",
      "[9]\ttraining's binary_logloss: 0.101863\ttraining's log_loss_: 0.173463\ttraining's accuracy: 0.940976\n",
      "[10]\ttraining's binary_logloss: -0.256271\ttraining's log_loss_: 0.162633\ttraining's accuracy: 0.944381\n",
      "[11]\ttraining's binary_logloss: -0.290062\ttraining's log_loss_: 0.143784\ttraining's accuracy: 0.947787\n",
      "[12]\ttraining's binary_logloss: -0.47829\ttraining's log_loss_: 0.157559\ttraining's accuracy: 0.961407\n",
      "[13]\ttraining's binary_logloss: -0.801751\ttraining's log_loss_: 0.162428\ttraining's accuracy: 0.970488\n",
      "[14]\ttraining's binary_logloss: -0.804317\ttraining's log_loss_: 0.248142\ttraining's accuracy: 0.967083\n",
      "[15]\ttraining's binary_logloss: -0.830464\ttraining's log_loss_: 0.246456\ttraining's accuracy: 0.968218\n",
      "[16]\ttraining's binary_logloss: -0.817503\ttraining's log_loss_: 0.244772\ttraining's accuracy: 0.969353\n",
      "[17]\ttraining's binary_logloss: -0.942551\ttraining's log_loss_: 0.249156\ttraining's accuracy: 0.969353\n",
      "[18]\ttraining's binary_logloss: -0.848502\ttraining's log_loss_: 0.284877\ttraining's accuracy: 0.969353\n",
      "[19]\ttraining's binary_logloss: -0.86262\ttraining's log_loss_: 0.290558\ttraining's accuracy: 0.971623\n",
      "[20]\ttraining's binary_logloss: -1.03141\ttraining's log_loss_: 0.271043\ttraining's accuracy: 0.976163\n",
      "[21]\ttraining's binary_logloss: -1.06122\ttraining's log_loss_: 0.308559\ttraining's accuracy: 0.970488\n",
      "[22]\ttraining's binary_logloss: -0.874166\ttraining's log_loss_: 0.404511\ttraining's accuracy: 0.969353\n",
      "[23]\ttraining's binary_logloss: -1.06985\ttraining's log_loss_: 0.287494\ttraining's accuracy: 0.972758\n",
      "[24]\ttraining's binary_logloss: -0.792774\ttraining's log_loss_: 0.493957\ttraining's accuracy: 0.962543\n",
      "[25]\ttraining's binary_logloss: -1.13523\ttraining's log_loss_: 0.296015\ttraining's accuracy: 0.969353\n",
      "[26]\ttraining's binary_logloss: -1.03765\ttraining's log_loss_: 0.401715\ttraining's accuracy: 0.970488\n",
      "[27]\ttraining's binary_logloss: -1.00193\ttraining's log_loss_: 0.495769\ttraining's accuracy: 0.967083\n",
      "[28]\ttraining's binary_logloss: -1.08127\ttraining's log_loss_: 0.47846\ttraining's accuracy: 0.968218\n",
      "[29]\ttraining's binary_logloss: -0.966393\ttraining's log_loss_: 0.622724\ttraining's accuracy: 0.961407\n",
      "[30]\ttraining's binary_logloss: -0.489884\ttraining's log_loss_: 1.14435\ttraining's accuracy: 0.946652\n",
      "[31]\ttraining's binary_logloss: -1.01256\ttraining's log_loss_: 0.811632\ttraining's accuracy: 0.956867\n",
      "[32]\ttraining's binary_logloss: -1.02431\ttraining's log_loss_: 0.869303\ttraining's accuracy: 0.955732\n",
      "[33]\ttraining's binary_logloss: -1.33584\ttraining's log_loss_: 0.657062\ttraining's accuracy: 0.960272\n",
      "[34]\ttraining's binary_logloss: -1.15221\ttraining's log_loss_: 0.831258\ttraining's accuracy: 0.954597\n",
      "[35]\ttraining's binary_logloss: -1.35538\ttraining's log_loss_: 0.756482\ttraining's accuracy: 0.958002\n",
      "[36]\ttraining's binary_logloss: -1.43426\ttraining's log_loss_: 0.736533\ttraining's accuracy: 0.959137\n",
      "[37]\ttraining's binary_logloss: -0.28645\ttraining's log_loss_: 1.61886\ttraining's accuracy: 0.93076\n",
      "[38]\ttraining's binary_logloss: 0.176808\ttraining's log_loss_: 2.01826\ttraining's accuracy: 0.913734\n",
      "[39]\ttraining's binary_logloss: -0.317702\ttraining's log_loss_: 1.9266\ttraining's accuracy: 0.927355\n",
      "[40]\ttraining's binary_logloss: -0.442357\ttraining's log_loss_: 1.68756\ttraining's accuracy: 0.92622\n",
      "[41]\ttraining's binary_logloss: -0.603903\ttraining's log_loss_: 1.60064\ttraining's accuracy: 0.929625\n",
      "[42]\ttraining's binary_logloss: -0.563898\ttraining's log_loss_: 1.71111\ttraining's accuracy: 0.92622\n",
      "[43]\ttraining's binary_logloss: -0.434499\ttraining's log_loss_: 1.85645\ttraining's accuracy: 0.92395\n",
      "[44]\ttraining's binary_logloss: -0.0515926\ttraining's log_loss_: 2.30492\ttraining's accuracy: 0.912599\n",
      "[45]\ttraining's binary_logloss: 0.62291\ttraining's log_loss_: 3.06188\ttraining's accuracy: 0.884222\n",
      "[46]\ttraining's binary_logloss: 2.01134\ttraining's log_loss_: 4.12641\ttraining's accuracy: 0.851305\n",
      "[47]\ttraining's binary_logloss: 1.13626\ttraining's log_loss_: 3.4811\ttraining's accuracy: 0.871737\n",
      "[48]\ttraining's binary_logloss: 0.577602\ttraining's log_loss_: 3.19912\ttraining's accuracy: 0.875142\n",
      "[49]\ttraining's binary_logloss: 0.955112\ttraining's log_loss_: 3.61893\ttraining's accuracy: 0.868331\n",
      "[50]\ttraining's binary_logloss: 1.11095\ttraining's log_loss_: 3.8518\ttraining's accuracy: 0.863791\n",
      "[51]\ttraining's binary_logloss: 1.76833\ttraining's log_loss_: 4.30724\ttraining's accuracy: 0.8479\n",
      "[52]\ttraining's binary_logloss: 1.58044\ttraining's log_loss_: 4.10824\ttraining's accuracy: 0.849035\n",
      "[53]\ttraining's binary_logloss: 2.16094\ttraining's log_loss_: 4.85447\ttraining's accuracy: 0.830874\n",
      "[54]\ttraining's binary_logloss: 3.11987\ttraining's log_loss_: 5.68228\ttraining's accuracy: 0.804767\n",
      "[55]\ttraining's binary_logloss: 2.61904\ttraining's log_loss_: 5.3926\ttraining's accuracy: 0.813848\n",
      "[56]\ttraining's binary_logloss: 1.96793\ttraining's log_loss_: 5.20562\ttraining's accuracy: 0.828604\n",
      "[57]\ttraining's binary_logloss: 2.73811\ttraining's log_loss_: 5.96105\ttraining's accuracy: 0.801362\n",
      "[58]\ttraining's binary_logloss: 2.16021\ttraining's log_loss_: 5.59661\ttraining's accuracy: 0.812713\n",
      "[59]\ttraining's binary_logloss: 1.83987\ttraining's log_loss_: 5.38335\ttraining's accuracy: 0.820658\n",
      "[60]\ttraining's binary_logloss: 1.67051\ttraining's log_loss_: 5.31475\ttraining's accuracy: 0.821793\n",
      "[61]\ttraining's binary_logloss: 1.51001\ttraining's log_loss_: 5.14647\ttraining's accuracy: 0.822928\n",
      "[62]\ttraining's binary_logloss: 2.89428\ttraining's log_loss_: 6.36347\ttraining's accuracy: 0.779796\n",
      "[63]\ttraining's binary_logloss: 3.39992\ttraining's log_loss_: 6.72495\ttraining's accuracy: 0.768445\n",
      "[64]\ttraining's binary_logloss: 3.64674\ttraining's log_loss_: 7.27899\ttraining's accuracy: 0.759364\n",
      "[65]\ttraining's binary_logloss: 2.45963\ttraining's log_loss_: 6.42358\ttraining's accuracy: 0.77639\n",
      "[66]\ttraining's binary_logloss: 2.71651\ttraining's log_loss_: 6.93654\ttraining's accuracy: 0.76958\n",
      "[67]\ttraining's binary_logloss: 4.01924\ttraining's log_loss_: 8.44458\ttraining's accuracy: 0.732123\n",
      "[68]\ttraining's binary_logloss: 4.57525\ttraining's log_loss_: 9.18432\ttraining's accuracy: 0.716232\n",
      "[69]\ttraining's binary_logloss: 4.36031\ttraining's log_loss_: 9.49842\ttraining's accuracy: 0.711691\n",
      "[70]\ttraining's binary_logloss: 5.37169\ttraining's log_loss_: 10.4866\ttraining's accuracy: 0.685585\n",
      "[71]\ttraining's binary_logloss: 4.11333\ttraining's log_loss_: 9.53581\ttraining's accuracy: 0.712826\n",
      "[72]\ttraining's binary_logloss: 7.96819\ttraining's log_loss_: 13.0196\ttraining's accuracy: 0.61067\n",
      "[73]\ttraining's binary_logloss: -0.0797287\ttraining's log_loss_: 7.5039\ttraining's accuracy: 0.777526\n",
      "[74]\ttraining's binary_logloss: -0.680741\ttraining's log_loss_: 7.22796\ttraining's accuracy: 0.788876\n",
      "[75]\ttraining's binary_logloss: -0.142345\ttraining's log_loss_: 7.79035\ttraining's accuracy: 0.772985\n",
      "[76]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[77]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[78]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[79]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[80]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[81]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[82]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[83]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[84]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[85]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[86]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[87]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[88]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[90]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[91]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[92]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[93]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[94]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[95]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[96]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[97]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[98]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[99]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[100]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[101]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[102]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[103]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[104]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[105]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[106]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[107]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[108]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[109]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[110]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[111]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[112]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[113]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[114]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[115]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[116]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[117]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[118]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[119]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[120]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[121]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[122]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[123]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[124]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[125]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[126]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[127]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[128]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[129]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[130]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[131]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[132]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[133]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[134]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[135]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[136]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[137]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[138]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[139]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[140]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[141]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[142]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[143]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[144]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[145]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[146]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[147]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[148]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[149]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[150]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[151]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[152]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[153]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[154]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[155]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[156]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[157]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[158]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[159]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[160]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[161]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[162]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[163]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[164]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[165]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[166]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[167]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[168]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[169]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[170]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[171]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[172]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[173]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[174]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[175]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[176]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[177]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[178]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[179]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[180]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[181]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[182]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[183]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[184]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[185]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[186]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[187]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[188]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[189]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[190]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[191]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[192]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[193]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[194]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[195]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[196]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[197]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[198]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[199]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[200]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[201]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[202]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[203]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[204]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[205]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[206]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[207]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[208]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[209]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[210]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[211]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[212]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[213]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[214]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[215]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[216]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[217]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[218]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[219]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[220]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[221]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[222]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[223]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[224]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[225]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[226]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[227]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[228]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[229]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[230]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[231]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[232]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[233]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[234]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[235]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[236]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[237]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[238]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[239]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[240]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[241]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[242]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[243]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[244]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[245]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[246]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[247]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[248]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[249]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[250]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[251]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[252]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[253]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[254]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[255]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[256]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[257]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[258]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[259]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[260]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[261]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[262]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[263]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[264]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[265]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[266]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[267]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[268]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[269]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[270]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[271]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[272]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[273]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[274]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[275]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[276]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[277]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[278]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[279]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[280]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[281]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[282]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[283]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[284]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[285]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[286]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[287]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[288]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[289]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[290]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[291]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[292]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[293]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[294]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[295]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[296]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[297]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[298]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[299]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[300]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[301]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[302]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[303]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[304]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[305]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[306]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[307]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[308]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[309]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[310]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[311]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[312]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[313]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[314]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[315]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[316]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[317]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[318]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[319]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[320]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[321]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[322]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[323]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[324]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[325]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[326]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[327]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[328]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[329]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[330]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[331]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[332]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[333]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[334]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[335]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[336]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[337]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[338]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[339]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[340]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[341]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[342]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[343]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[344]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[345]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[346]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[347]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[348]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[349]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[350]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[351]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[352]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[353]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[354]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[355]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[356]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[357]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[358]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[359]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[360]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[361]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[362]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[363]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[364]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[365]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[366]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[367]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[368]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[369]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[370]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[371]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[372]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[373]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[374]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[375]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[376]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[377]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[378]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[379]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[380]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[381]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[382]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[383]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[384]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[385]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[386]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[387]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[388]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[389]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[390]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[391]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[392]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[393]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[394]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[395]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[396]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[397]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[398]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[399]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[400]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[401]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[402]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[403]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[404]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[405]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[406]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[407]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[408]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[409]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[410]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[411]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[412]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[413]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[414]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[415]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[416]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[417]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[418]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[419]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[420]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[421]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[422]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[423]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[424]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[425]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[426]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[427]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[428]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[429]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[430]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[431]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[432]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[433]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[434]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[435]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[436]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[437]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[438]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[439]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[440]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[441]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[442]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[443]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[444]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[445]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[446]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[447]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[448]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[449]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[450]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[451]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[452]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[453]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[454]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[455]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[456]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[457]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[458]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[459]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[460]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[461]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[462]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[463]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[464]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[465]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[466]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[467]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[468]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[469]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[470]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[471]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[472]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[473]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[474]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[475]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[476]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[477]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[478]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[479]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[480]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[481]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[482]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[483]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[484]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[485]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[486]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[487]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[488]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[489]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[490]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[491]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[492]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[493]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[494]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[495]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[496]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[497]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[498]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[499]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[500]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[501]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[502]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[503]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[504]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[505]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[506]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[507]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[508]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[509]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[510]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[511]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[512]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[513]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[514]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[515]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[516]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[517]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[518]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[519]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[520]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[521]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[522]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[523]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[524]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[525]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[526]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[527]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[528]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[529]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[530]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[531]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[532]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[533]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[534]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[535]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[536]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[537]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[538]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[539]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[540]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[541]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[542]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[543]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[544]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[545]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[546]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[547]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[548]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[549]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[550]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[551]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[552]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[553]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[554]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[555]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[556]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[557]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[558]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[559]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[560]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[561]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[562]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[563]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[564]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[565]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[566]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[567]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[568]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[569]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[570]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[571]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[572]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[573]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[574]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[575]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[576]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[577]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[578]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[579]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[580]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[581]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[582]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[583]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[584]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[585]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[586]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[587]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[588]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[589]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[590]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[591]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[592]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[593]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[594]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[595]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[596]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[597]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[598]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[599]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[600]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[601]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[602]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[603]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[604]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[605]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[606]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[607]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[608]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[609]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[610]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[611]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[612]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[613]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[614]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[615]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[616]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[617]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[618]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[619]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[620]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[621]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[622]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[623]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[624]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[625]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[626]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[627]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[628]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[629]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[630]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[631]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[632]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[633]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[634]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[635]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[636]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[637]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[638]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[639]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[640]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[641]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[642]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[643]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[644]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[645]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[646]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[647]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[648]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[649]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[650]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[651]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[652]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[653]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[654]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[655]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[656]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[657]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[658]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[659]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[660]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[661]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[662]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[663]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[664]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[665]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[666]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[667]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[668]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[669]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[670]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[671]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[672]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[673]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[674]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[675]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[676]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[677]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[678]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[679]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[680]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[681]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[682]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[683]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[684]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[685]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[686]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[687]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[688]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[689]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[690]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[691]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[692]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[693]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[694]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[695]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[696]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[697]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[698]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[699]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[700]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[701]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[702]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[703]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[704]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[705]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[706]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[707]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[708]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[709]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[710]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[711]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[712]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[713]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[714]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[715]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[716]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[717]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[718]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[719]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[720]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[721]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[722]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[723]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[724]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[725]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[726]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[727]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[728]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[729]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[730]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[731]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[732]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[733]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[734]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[735]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[736]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[737]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[738]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[739]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[740]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[741]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[742]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[743]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[744]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[745]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[746]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[747]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[748]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[749]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[750]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[751]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[752]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[753]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[754]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[755]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[756]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[757]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[758]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[759]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[760]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[761]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[762]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[763]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[764]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[765]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[766]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[767]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[768]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[769]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[770]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[771]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[772]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[773]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[774]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[775]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[776]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[777]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[778]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[779]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[780]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[781]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[782]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[783]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[784]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[785]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[786]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[787]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[788]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[789]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[790]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[791]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[792]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[793]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[794]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[795]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[796]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[797]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[798]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[799]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[800]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[801]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[802]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[803]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[804]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[805]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[806]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[807]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[808]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[809]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[810]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[811]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[812]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[813]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[814]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[815]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[816]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[817]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[818]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[819]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[820]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[821]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[822]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[823]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[824]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[825]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[826]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[827]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[828]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[829]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[830]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[831]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[832]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[833]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[834]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[835]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[836]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[837]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[838]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[839]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[840]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[841]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[842]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[843]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[844]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[845]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[846]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[847]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[848]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[849]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[850]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[851]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[852]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[853]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[854]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[855]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[856]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[857]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[858]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[859]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[860]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[861]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[862]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[863]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[864]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[865]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[866]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[867]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[868]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[869]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[870]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[871]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[872]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[873]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[874]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[875]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[876]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[877]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[878]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[879]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[880]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[881]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[882]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[883]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[884]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[885]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[886]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[887]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[888]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[889]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[890]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[891]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[892]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[893]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[894]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[895]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[896]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[897]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[898]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[899]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[900]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[901]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[902]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[903]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[904]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[905]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[906]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[907]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[908]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[909]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[910]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[911]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[912]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[913]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[914]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[915]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[916]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[917]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[918]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[919]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[920]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[921]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[922]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[923]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[924]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[925]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[926]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[927]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[928]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[929]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[930]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[931]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[932]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[933]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[934]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[935]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[936]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[937]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[938]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[939]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[940]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[941]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[942]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[943]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[944]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[945]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[946]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[947]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[948]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[949]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[950]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[951]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[952]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[953]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[954]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[955]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[956]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[957]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[958]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[959]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[960]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[961]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[962]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[963]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[964]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[965]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[966]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[967]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[968]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[969]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[970]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[971]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[972]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[973]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[974]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[975]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[976]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[977]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[978]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[979]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[980]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[981]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[982]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[983]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[984]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[985]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[986]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[987]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[988]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[989]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[990]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[991]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[992]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[993]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[994]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[995]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[996]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[997]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[998]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[999]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[1000]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "0.7854710556186152\n",
      "0.7854710556186152\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "lgb_train = lgb.Dataset(X, y, free_raw_data=False)\n",
    "lgb_eval = lgb.Dataset(X, y, free_raw_data=False)\n",
    "\n",
    "\n",
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, eval_result: float, is_higher_better: bool\n",
    "# binary error\n",
    "def binary_error(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'binary_errorrr', np.mean(labels != (preds > 0.5)), False\n",
    "\n",
    "\n",
    "\n",
    "def accuracy(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'accuracy', np.mean(labels == (preds > 0.5)), True\n",
    "\n",
    "\n",
    "\n",
    "def log_loss_(preds, train_data):\n",
    "    y_preds = 1. / (1. + np.exp(-preds))\n",
    "    labels = train_data.get_label()\n",
    "    return 'log_loss_', log_loss(labels, y_preds), True\n",
    "\n",
    "\n",
    "\n",
    "# log likelihood loss\n",
    "def loglikelihood(preds, train_data): #preds here is not y_pred, it's the sum_linear_pred (raw pred)\n",
    "    labels = train_data.get_label()\n",
    "    preds = 1. / (1. + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1. - preds)\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "\n",
    "params = {}\n",
    "params = {}\n",
    "params['learning_rate'] = 1\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'binary'\n",
    "params['metric'] = 'binary'\n",
    "params['sub_feature'] = 1\n",
    "params['num_leaves'] = 31\n",
    "params['min_data'] = 0\n",
    "params['max_depth'] = max_depth_tree\n",
    "params['reg_alpha'] = 0\n",
    "params['reg_lambda'] = 0\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=num_trees,\n",
    "                fobj=loglikelihood,\n",
    "                feval=lambda preds, train_data: [log_loss_(preds, train_data),\n",
    "                                                 accuracy(preds, train_data)],\n",
    "                valid_sets=lgb_train)\n",
    "\n",
    "y_pred = gbm.predict(X, num_iteration=gbm.best_iteration)\n",
    "\n",
    "print(1-np.mean(y != (y_pred > 0.5)))\n",
    "\n",
    "\n",
    "temp = 1. / (1. + np.exp(-y_pred))\n",
    "print(1-np.mean(y != (temp > 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8910329171396141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.547105561861521"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(accuracy_score(res_2, y))\n",
    "accuracy_score(res_2, y) == (1-np.mean(y != (y_pred > 0.5)))\n",
    "(1-np.mean(y != (y_pred > 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm.create_tree_digraph(m2, tree_index=0, show_info=[\"split_gain\", \"internal_value\", \"internal_count\", \"leaf_count\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm.create_tree_digraph(gbm, tree_index=0, show_info=[\"split_gain\", \"internal_value\", \"internal_count\", \"leaf_count\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    preds = 1. / (1. + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1. - preds)\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, eval_result: float, is_higher_better: bool\n",
    "# binary error\n",
    "def binary_error(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'error', np.mean(labels != (preds > 0.5)), False\n",
    "\n",
    "\n",
    "print('Finished 40 - 50 rounds with self-defined objective function and eval metric...')\n",
    "\n",
    "\n",
    "# another self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, eval_result: float, is_higher_better: bool\n",
    "# accuracy\n",
    "def accuracy(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'accuracy', np.mean(labels == (preds > 0.5)), True\n",
    "\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                fobj=loglikelihood,\n",
    "                feval=lambda preds, train_data: [binary_error(preds, train_data),\n",
    "                                                 accuracy(preds, train_data)],\n",
    "                valid_sets=lgb_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X, num_iteration=gbm.best_iteration) > 0.5\n",
    "accuracy_score(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objetive = binary   => regresson on (0,1) => 1.1 => sigmoid(1.1) (this is y_pred) => calc error => finish 1 round, return  y_pred=sigmoid(1.1) \n",
    "\n",
    "objetive = log_loss_customer_func   => regresson on (0,1) => 1.1 (this is y_pred) => sigmoid(1.1) => calc error => finish 1 round,  return  y_pred=1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hessian ?\n",
    "how to find best split\n",
    "how to minimize error after know index for best split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "py3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
