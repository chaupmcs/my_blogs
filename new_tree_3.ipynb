{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "import lightgbm\n",
    "\n",
    "# read pickle\n",
    "with open('./data/X.pickle', 'rb') as handle:\n",
    "    X = pickle.load(handle)\n",
    "    \n",
    "with open('./data/y.pickle', 'rb') as handle:\n",
    "    y = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.364431\n",
      "[2]\ttraining's binary_logloss: 0.30797\n",
      "[3]\ttraining's binary_logloss: 0.258656\n",
      "[4]\ttraining's binary_logloss: 0.239413\n",
      "[5]\ttraining's binary_logloss: 0.213851\n",
      "[6]\ttraining's binary_logloss: 0.204589\n",
      "[7]\ttraining's binary_logloss: 0.199272\n",
      "[8]\ttraining's binary_logloss: 0.193588\n",
      "[9]\ttraining's binary_logloss: 0.18745\n",
      "[10]\ttraining's binary_logloss: 0.172793\n",
      "[11]\ttraining's binary_logloss: 0.154085\n",
      "[12]\ttraining's binary_logloss: 0.150774\n",
      "[13]\ttraining's binary_logloss: 0.130422\n",
      "[14]\ttraining's binary_logloss: 0.118352\n",
      "[15]\ttraining's binary_logloss: 0.108654\n",
      "[16]\ttraining's binary_logloss: 0.09286\n",
      "[17]\ttraining's binary_logloss: 0.0890692\n",
      "[18]\ttraining's binary_logloss: 0.0813644\n",
      "[19]\ttraining's binary_logloss: 0.0745611\n",
      "[20]\ttraining's binary_logloss: 0.0607006\n",
      "[21]\ttraining's binary_logloss: 0.0568307\n",
      "[22]\ttraining's binary_logloss: 0.0529939\n",
      "[23]\ttraining's binary_logloss: 0.0461759\n",
      "[24]\ttraining's binary_logloss: 0.0445376\n",
      "[25]\ttraining's binary_logloss: 0.0421364\n",
      "[26]\ttraining's binary_logloss: 0.0413719\n",
      "[27]\ttraining's binary_logloss: 0.0403588\n",
      "[28]\ttraining's binary_logloss: 0.0388418\n",
      "[29]\ttraining's binary_logloss: 0.0385785\n",
      "[30]\ttraining's binary_logloss: 0.0378878\n",
      "[31]\ttraining's binary_logloss: 0.0376597\n",
      "[32]\ttraining's binary_logloss: 0.0372146\n",
      "[33]\ttraining's binary_logloss: 0.0356148\n",
      "[34]\ttraining's binary_logloss: 0.0352078\n",
      "[35]\ttraining's binary_logloss: 0.0345191\n",
      "[36]\ttraining's binary_logloss: 0.0340592\n",
      "[37]\ttraining's binary_logloss: 0.0323287\n",
      "[38]\ttraining's binary_logloss: 0.031008\n",
      "[39]\ttraining's binary_logloss: 0.0308502\n",
      "[40]\ttraining's binary_logloss: 0.0307101\n",
      "[41]\ttraining's binary_logloss: 0.0306353\n",
      "[42]\ttraining's binary_logloss: 0.0301245\n",
      "[43]\ttraining's binary_logloss: 0.0297772\n",
      "[44]\ttraining's binary_logloss: 0.0290038\n",
      "[45]\ttraining's binary_logloss: 0.0284422\n",
      "[46]\ttraining's binary_logloss: 0.0282804\n",
      "[47]\ttraining's binary_logloss: 0.0280888\n",
      "[48]\ttraining's binary_logloss: 0.0279177\n",
      "[49]\ttraining's binary_logloss: 0.0278096\n",
      "[50]\ttraining's binary_logloss: 0.0274934\n",
      "[51]\ttraining's binary_logloss: 0.0271724\n",
      "[52]\ttraining's binary_logloss: 0.0270119\n",
      "[53]\ttraining's binary_logloss: 0.0268759\n",
      "[54]\ttraining's binary_logloss: 0.0268392\n",
      "[55]\ttraining's binary_logloss: 0.0268169\n",
      "[56]\ttraining's binary_logloss: 0.0266182\n",
      "[57]\ttraining's binary_logloss: 0.0264948\n",
      "[58]\ttraining's binary_logloss: 0.0263624\n",
      "[59]\ttraining's binary_logloss: 0.0262428\n",
      "[60]\ttraining's binary_logloss: 0.0262319\n",
      "[61]\ttraining's binary_logloss: 0.0262189\n",
      "[62]\ttraining's binary_logloss: 0.026185\n",
      "[63]\ttraining's binary_logloss: 0.0261446\n",
      "[64]\ttraining's binary_logloss: 0.0261288\n",
      "[65]\ttraining's binary_logloss: 0.0261131\n",
      "[66]\ttraining's binary_logloss: 0.0260995\n",
      "[67]\ttraining's binary_logloss: 0.0260822\n",
      "[68]\ttraining's binary_logloss: 0.0259353\n",
      "[69]\ttraining's binary_logloss: 0.0255589\n",
      "[70]\ttraining's binary_logloss: 0.0254019\n",
      "[71]\ttraining's binary_logloss: 0.0253824\n",
      "[72]\ttraining's binary_logloss: 0.0252899\n",
      "[73]\ttraining's binary_logloss: 0.0252332\n",
      "[74]\ttraining's binary_logloss: 0.0252174\n",
      "[75]\ttraining's binary_logloss: 0.0251745\n",
      "[76]\ttraining's binary_logloss: 0.0251688\n",
      "[77]\ttraining's binary_logloss: 0.0251668\n",
      "[78]\ttraining's binary_logloss: 0.0251379\n",
      "[79]\ttraining's binary_logloss: 0.0251352\n",
      "[80]\ttraining's binary_logloss: 0.0251315\n",
      "[81]\ttraining's binary_logloss: 0.0250722\n",
      "[82]\ttraining's binary_logloss: 0.0250701\n",
      "[83]\ttraining's binary_logloss: 0.025069\n",
      "[84]\ttraining's binary_logloss: 0.0250414\n",
      "[85]\ttraining's binary_logloss: 0.0250215\n",
      "[86]\ttraining's binary_logloss: 0.0249992\n",
      "[87]\ttraining's binary_logloss: 0.0249969\n",
      "[88]\ttraining's binary_logloss: 0.0249943\n",
      "[89]\ttraining's binary_logloss: 0.0249936\n",
      "[90]\ttraining's binary_logloss: 0.0249928\n",
      "[91]\ttraining's binary_logloss: 0.024968\n",
      "[92]\ttraining's binary_logloss: 0.0249655\n",
      "[93]\ttraining's binary_logloss: 0.0249632\n",
      "[94]\ttraining's binary_logloss: 0.0249603\n",
      "[95]\ttraining's binary_logloss: 0.0249598\n",
      "[96]\ttraining's binary_logloss: 0.0249518\n",
      "[97]\ttraining's binary_logloss: 0.0249508\n",
      "[98]\ttraining's binary_logloss: 0.0249502\n",
      "[99]\ttraining's binary_logloss: 0.0249497\n",
      "[100]\ttraining's binary_logloss: 0.0249478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9875141884222475"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth_tree =5\n",
    "num_trees=100\n",
    "\n",
    "m2 = lightgbm.LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "        importance_type='split', learning_rate=1, max_depth=max_depth_tree,\n",
    "        min_child_samples=1, min_child_weight=0, min_split_gain=0.0,\n",
    "        n_estimators=num_trees, n_jobs=-1, num_leaves=31, objective=\"binary\", \n",
    "        random_state=1, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
    "m2.fit(X, y, verbose=1, eval_set = [(X,y)])\n",
    "\n",
    "res_2 = m2.predict(X)\n",
    "\n",
    "accuracy_score(res_2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 2.6015\ttraining's log_loss_: 0.369754\ttraining's accuracy: 0.830874\n",
      "[2]\ttraining's binary_logloss: 1.76144\ttraining's log_loss_: 0.316638\ttraining's accuracy: 0.860386\n",
      "[3]\ttraining's binary_logloss: 2.14285\ttraining's log_loss_: 0.282993\ttraining's accuracy: 0.896708\n",
      "[4]\ttraining's binary_logloss: 1.26876\ttraining's log_loss_: 0.245081\ttraining's accuracy: 0.911464\n",
      "[5]\ttraining's binary_logloss: 1.03233\ttraining's log_loss_: 0.228174\ttraining's accuracy: 0.914869\n",
      "[6]\ttraining's binary_logloss: 0.673541\ttraining's log_loss_: 0.198358\ttraining's accuracy: 0.92622\n",
      "[7]\ttraining's binary_logloss: 0.371114\ttraining's log_loss_: 0.182951\ttraining's accuracy: 0.934166\n",
      "[8]\ttraining's binary_logloss: 0.329367\ttraining's log_loss_: 0.212572\ttraining's accuracy: 0.929625\n",
      "[9]\ttraining's binary_logloss: 0.101863\ttraining's log_loss_: 0.173463\ttraining's accuracy: 0.940976\n",
      "[10]\ttraining's binary_logloss: -0.256271\ttraining's log_loss_: 0.162633\ttraining's accuracy: 0.944381\n",
      "[11]\ttraining's binary_logloss: -0.290062\ttraining's log_loss_: 0.143784\ttraining's accuracy: 0.947787\n",
      "[12]\ttraining's binary_logloss: -0.47829\ttraining's log_loss_: 0.157559\ttraining's accuracy: 0.961407\n",
      "[13]\ttraining's binary_logloss: -0.801751\ttraining's log_loss_: 0.162428\ttraining's accuracy: 0.970488\n",
      "[14]\ttraining's binary_logloss: -0.804317\ttraining's log_loss_: 0.248142\ttraining's accuracy: 0.967083\n",
      "[15]\ttraining's binary_logloss: -0.830464\ttraining's log_loss_: 0.246456\ttraining's accuracy: 0.968218\n",
      "[16]\ttraining's binary_logloss: -0.817503\ttraining's log_loss_: 0.244772\ttraining's accuracy: 0.969353\n",
      "[17]\ttraining's binary_logloss: -0.942551\ttraining's log_loss_: 0.249156\ttraining's accuracy: 0.969353\n",
      "[18]\ttraining's binary_logloss: -0.848502\ttraining's log_loss_: 0.284877\ttraining's accuracy: 0.969353\n",
      "[19]\ttraining's binary_logloss: -0.86262\ttraining's log_loss_: 0.290558\ttraining's accuracy: 0.971623\n",
      "[20]\ttraining's binary_logloss: -1.03141\ttraining's log_loss_: 0.271043\ttraining's accuracy: 0.976163\n",
      "[21]\ttraining's binary_logloss: -1.06122\ttraining's log_loss_: 0.308559\ttraining's accuracy: 0.970488\n",
      "[22]\ttraining's binary_logloss: -0.874166\ttraining's log_loss_: 0.404511\ttraining's accuracy: 0.969353\n",
      "[23]\ttraining's binary_logloss: -1.06985\ttraining's log_loss_: 0.287494\ttraining's accuracy: 0.972758\n",
      "[24]\ttraining's binary_logloss: -0.792774\ttraining's log_loss_: 0.493957\ttraining's accuracy: 0.962543\n",
      "[25]\ttraining's binary_logloss: -1.13523\ttraining's log_loss_: 0.296015\ttraining's accuracy: 0.969353\n",
      "[26]\ttraining's binary_logloss: -1.03765\ttraining's log_loss_: 0.401715\ttraining's accuracy: 0.970488\n",
      "[27]\ttraining's binary_logloss: -1.00193\ttraining's log_loss_: 0.495769\ttraining's accuracy: 0.967083\n",
      "[28]\ttraining's binary_logloss: -1.08127\ttraining's log_loss_: 0.47846\ttraining's accuracy: 0.968218\n",
      "[29]\ttraining's binary_logloss: -0.966393\ttraining's log_loss_: 0.622724\ttraining's accuracy: 0.961407\n",
      "[30]\ttraining's binary_logloss: -0.489884\ttraining's log_loss_: 1.14435\ttraining's accuracy: 0.946652\n",
      "[31]\ttraining's binary_logloss: -1.01256\ttraining's log_loss_: 0.811632\ttraining's accuracy: 0.956867\n",
      "[32]\ttraining's binary_logloss: -1.02431\ttraining's log_loss_: 0.869303\ttraining's accuracy: 0.955732\n",
      "[33]\ttraining's binary_logloss: -1.33584\ttraining's log_loss_: 0.657062\ttraining's accuracy: 0.960272\n",
      "[34]\ttraining's binary_logloss: -1.15221\ttraining's log_loss_: 0.831258\ttraining's accuracy: 0.954597\n",
      "[35]\ttraining's binary_logloss: -1.35538\ttraining's log_loss_: 0.756482\ttraining's accuracy: 0.958002\n",
      "[36]\ttraining's binary_logloss: -1.43426\ttraining's log_loss_: 0.736533\ttraining's accuracy: 0.959137\n",
      "[37]\ttraining's binary_logloss: -0.28645\ttraining's log_loss_: 1.61886\ttraining's accuracy: 0.93076\n",
      "[38]\ttraining's binary_logloss: 0.176808\ttraining's log_loss_: 2.01826\ttraining's accuracy: 0.913734\n",
      "[39]\ttraining's binary_logloss: -0.317702\ttraining's log_loss_: 1.9266\ttraining's accuracy: 0.927355\n",
      "[40]\ttraining's binary_logloss: -0.442357\ttraining's log_loss_: 1.68756\ttraining's accuracy: 0.92622\n",
      "[41]\ttraining's binary_logloss: -0.603903\ttraining's log_loss_: 1.60064\ttraining's accuracy: 0.929625\n",
      "[42]\ttraining's binary_logloss: -0.563898\ttraining's log_loss_: 1.71111\ttraining's accuracy: 0.92622\n",
      "[43]\ttraining's binary_logloss: -0.434499\ttraining's log_loss_: 1.85645\ttraining's accuracy: 0.92395\n",
      "[44]\ttraining's binary_logloss: -0.0515926\ttraining's log_loss_: 2.30492\ttraining's accuracy: 0.912599\n",
      "[45]\ttraining's binary_logloss: 0.62291\ttraining's log_loss_: 3.06188\ttraining's accuracy: 0.884222\n",
      "[46]\ttraining's binary_logloss: 2.01134\ttraining's log_loss_: 4.12641\ttraining's accuracy: 0.851305\n",
      "[47]\ttraining's binary_logloss: 1.13626\ttraining's log_loss_: 3.4811\ttraining's accuracy: 0.871737\n",
      "[48]\ttraining's binary_logloss: 0.577602\ttraining's log_loss_: 3.19912\ttraining's accuracy: 0.875142\n",
      "[49]\ttraining's binary_logloss: 0.955112\ttraining's log_loss_: 3.61893\ttraining's accuracy: 0.868331\n",
      "[50]\ttraining's binary_logloss: 1.11095\ttraining's log_loss_: 3.8518\ttraining's accuracy: 0.863791\n",
      "[51]\ttraining's binary_logloss: 1.76833\ttraining's log_loss_: 4.30724\ttraining's accuracy: 0.8479\n",
      "[52]\ttraining's binary_logloss: 1.58044\ttraining's log_loss_: 4.10824\ttraining's accuracy: 0.849035\n",
      "[53]\ttraining's binary_logloss: 2.16094\ttraining's log_loss_: 4.85447\ttraining's accuracy: 0.830874\n",
      "[54]\ttraining's binary_logloss: 3.11987\ttraining's log_loss_: 5.68228\ttraining's accuracy: 0.804767\n",
      "[55]\ttraining's binary_logloss: 2.61904\ttraining's log_loss_: 5.3926\ttraining's accuracy: 0.813848\n",
      "[56]\ttraining's binary_logloss: 1.96793\ttraining's log_loss_: 5.20562\ttraining's accuracy: 0.828604\n",
      "[57]\ttraining's binary_logloss: 2.73811\ttraining's log_loss_: 5.96105\ttraining's accuracy: 0.801362\n",
      "[58]\ttraining's binary_logloss: 2.16021\ttraining's log_loss_: 5.59661\ttraining's accuracy: 0.812713\n",
      "[59]\ttraining's binary_logloss: 1.83987\ttraining's log_loss_: 5.38335\ttraining's accuracy: 0.820658\n",
      "[60]\ttraining's binary_logloss: 1.67051\ttraining's log_loss_: 5.31475\ttraining's accuracy: 0.821793\n",
      "[61]\ttraining's binary_logloss: 1.51001\ttraining's log_loss_: 5.14647\ttraining's accuracy: 0.822928\n",
      "[62]\ttraining's binary_logloss: 2.89428\ttraining's log_loss_: 6.36347\ttraining's accuracy: 0.779796\n",
      "[63]\ttraining's binary_logloss: 3.39992\ttraining's log_loss_: 6.72495\ttraining's accuracy: 0.768445\n",
      "[64]\ttraining's binary_logloss: 3.64674\ttraining's log_loss_: 7.27899\ttraining's accuracy: 0.759364\n",
      "[65]\ttraining's binary_logloss: 2.45963\ttraining's log_loss_: 6.42358\ttraining's accuracy: 0.77639\n",
      "[66]\ttraining's binary_logloss: 2.71651\ttraining's log_loss_: 6.93654\ttraining's accuracy: 0.76958\n",
      "[67]\ttraining's binary_logloss: 4.01924\ttraining's log_loss_: 8.44458\ttraining's accuracy: 0.732123\n",
      "[68]\ttraining's binary_logloss: 4.57525\ttraining's log_loss_: 9.18432\ttraining's accuracy: 0.716232\n",
      "[69]\ttraining's binary_logloss: 4.36031\ttraining's log_loss_: 9.49842\ttraining's accuracy: 0.711691\n",
      "[70]\ttraining's binary_logloss: 5.37169\ttraining's log_loss_: 10.4866\ttraining's accuracy: 0.685585\n",
      "[71]\ttraining's binary_logloss: 4.11333\ttraining's log_loss_: 9.53581\ttraining's accuracy: 0.712826\n",
      "[72]\ttraining's binary_logloss: 7.96819\ttraining's log_loss_: 13.0196\ttraining's accuracy: 0.61067\n",
      "[73]\ttraining's binary_logloss: -0.0797287\ttraining's log_loss_: 7.5039\ttraining's accuracy: 0.777526\n",
      "[74]\ttraining's binary_logloss: -0.680741\ttraining's log_loss_: 7.22796\ttraining's accuracy: 0.788876\n",
      "[75]\ttraining's binary_logloss: -0.142345\ttraining's log_loss_: 7.79035\ttraining's accuracy: 0.772985\n",
      "[76]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[77]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[78]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[79]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[80]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[81]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[82]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[83]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[84]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[85]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[86]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[87]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[88]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[89]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[90]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[91]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[92]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[93]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[95]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[96]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[97]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[98]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[99]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "[100]\ttraining's binary_logloss: -0.792212\ttraining's log_loss_: 7.3343\ttraining's accuracy: 0.785471\n",
      "0.7854710556186152\n",
      "0.7854710556186152\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "lgb_train = lgb.Dataset(X, y, free_raw_data=False)\n",
    "lgb_eval = lgb.Dataset(X, y, free_raw_data=False)\n",
    "\n",
    "\n",
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, eval_result: float, is_higher_better: bool\n",
    "# binary error\n",
    "def binary_error(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'binary_errorrr', np.mean(labels != (preds > 0.5)), False\n",
    "\n",
    "\n",
    "\n",
    "def accuracy(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'accuracy', np.mean(labels == (preds > 0.5)), True\n",
    "\n",
    "\n",
    "\n",
    "def log_loss_(preds, train_data):\n",
    "    y_preds = 1. / (1. + np.exp(-preds))\n",
    "    labels = train_data.get_label()\n",
    "    return 'log_loss_', log_loss(labels, y_preds), True\n",
    "\n",
    "\n",
    "\n",
    "# log likelihood loss\n",
    "def loglikelihood(preds, train_data): #preds here is not y_pred, it's the sum_linear_pred (raw pred)\n",
    "    labels = train_data.get_label()\n",
    "    preds = 1. / (1. + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1. - preds)\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "\n",
    "params = {}\n",
    "params = {}\n",
    "params['learning_rate'] = 1\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'binary'\n",
    "params['metric'] = 'binary'\n",
    "params['sub_feature'] = 1\n",
    "params['num_leaves'] = 31\n",
    "params['min_data'] = 0\n",
    "params['max_depth'] = max_depth_tree\n",
    "params['reg_alpha'] = 0\n",
    "params['reg_lambda'] = 0\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=num_trees,\n",
    "                fobj=loglikelihood,\n",
    "                feval=lambda preds, train_data: [log_loss_(preds, train_data),\n",
    "                                                 accuracy(preds, train_data)],\n",
    "                valid_sets=lgb_train)\n",
    "\n",
    "y_pred = gbm.predict(X, num_iteration=gbm.best_iteration)\n",
    "\n",
    "print(1-np.mean(y != (y_pred > 0.5)))\n",
    "\n",
    "\n",
    "temp = 1. / (1. + np.exp(-y_pred))\n",
    "print(1-np.mean(y != (temp > 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9875141884222475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(accuracy_score(res_2, y))\n",
    "accuracy_score(res_2, y) == (1-np.mean(y != (y_pred > 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm.create_tree_digraph(m2, tree_index=0, show_info=[\"split_gain\", \"internal_value\", \"internal_count\", \"leaf_count\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm.create_tree_digraph(gbm, tree_index=0, show_info=[\"split_gain\", \"internal_value\", \"internal_count\", \"leaf_count\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 40 - 50 rounds with self-defined objective function and eval metric...\n",
      "[1]\tvalid_0's binary_logloss: 2.6015\tvalid_0's error: 0.169126\tvalid_0's accuracy: 0.830874\n",
      "[2]\tvalid_0's binary_logloss: 1.76144\tvalid_0's error: 0.139614\tvalid_0's accuracy: 0.860386\n",
      "[3]\tvalid_0's binary_logloss: 2.14285\tvalid_0's error: 0.103292\tvalid_0's accuracy: 0.896708\n",
      "[4]\tvalid_0's binary_logloss: 1.26876\tvalid_0's error: 0.0885358\tvalid_0's accuracy: 0.911464\n",
      "[5]\tvalid_0's binary_logloss: 1.03233\tvalid_0's error: 0.0851305\tvalid_0's accuracy: 0.914869\n",
      "[6]\tvalid_0's binary_logloss: 0.673541\tvalid_0's error: 0.0737798\tvalid_0's accuracy: 0.92622\n",
      "[7]\tvalid_0's binary_logloss: 0.371114\tvalid_0's error: 0.0658343\tvalid_0's accuracy: 0.934166\n",
      "[8]\tvalid_0's binary_logloss: 0.329367\tvalid_0's error: 0.0703746\tvalid_0's accuracy: 0.929625\n",
      "[9]\tvalid_0's binary_logloss: 0.101863\tvalid_0's error: 0.0590238\tvalid_0's accuracy: 0.940976\n",
      "[10]\tvalid_0's binary_logloss: -0.256271\tvalid_0's error: 0.0556186\tvalid_0's accuracy: 0.944381\n",
      "[11]\tvalid_0's binary_logloss: -0.290062\tvalid_0's error: 0.0522134\tvalid_0's accuracy: 0.947787\n",
      "[12]\tvalid_0's binary_logloss: -0.47829\tvalid_0's error: 0.0385925\tvalid_0's accuracy: 0.961407\n",
      "[13]\tvalid_0's binary_logloss: -0.801751\tvalid_0's error: 0.0295119\tvalid_0's accuracy: 0.970488\n",
      "[14]\tvalid_0's binary_logloss: -0.804317\tvalid_0's error: 0.0329171\tvalid_0's accuracy: 0.967083\n",
      "[15]\tvalid_0's binary_logloss: -0.830464\tvalid_0's error: 0.0317821\tvalid_0's accuracy: 0.968218\n",
      "[16]\tvalid_0's binary_logloss: -0.817503\tvalid_0's error: 0.030647\tvalid_0's accuracy: 0.969353\n",
      "[17]\tvalid_0's binary_logloss: -0.942551\tvalid_0's error: 0.030647\tvalid_0's accuracy: 0.969353\n",
      "[18]\tvalid_0's binary_logloss: -0.848502\tvalid_0's error: 0.030647\tvalid_0's accuracy: 0.969353\n",
      "[19]\tvalid_0's binary_logloss: -0.86262\tvalid_0's error: 0.0283768\tvalid_0's accuracy: 0.971623\n",
      "[20]\tvalid_0's binary_logloss: -1.03141\tvalid_0's error: 0.0238365\tvalid_0's accuracy: 0.976163\n",
      "[21]\tvalid_0's binary_logloss: -1.06122\tvalid_0's error: 0.0295119\tvalid_0's accuracy: 0.970488\n",
      "[22]\tvalid_0's binary_logloss: -0.874166\tvalid_0's error: 0.030647\tvalid_0's accuracy: 0.969353\n",
      "[23]\tvalid_0's binary_logloss: -1.06985\tvalid_0's error: 0.0272418\tvalid_0's accuracy: 0.972758\n",
      "[24]\tvalid_0's binary_logloss: -0.792774\tvalid_0's error: 0.0374574\tvalid_0's accuracy: 0.962543\n",
      "[25]\tvalid_0's binary_logloss: -1.13523\tvalid_0's error: 0.030647\tvalid_0's accuracy: 0.969353\n",
      "[26]\tvalid_0's binary_logloss: -1.03765\tvalid_0's error: 0.0295119\tvalid_0's accuracy: 0.970488\n",
      "[27]\tvalid_0's binary_logloss: -1.00193\tvalid_0's error: 0.0329171\tvalid_0's accuracy: 0.967083\n",
      "[28]\tvalid_0's binary_logloss: -1.08127\tvalid_0's error: 0.0317821\tvalid_0's accuracy: 0.968218\n",
      "[29]\tvalid_0's binary_logloss: -0.966393\tvalid_0's error: 0.0385925\tvalid_0's accuracy: 0.961407\n",
      "[30]\tvalid_0's binary_logloss: -0.489884\tvalid_0's error: 0.0533485\tvalid_0's accuracy: 0.946652\n",
      "[31]\tvalid_0's binary_logloss: -1.01256\tvalid_0's error: 0.0431328\tvalid_0's accuracy: 0.956867\n",
      "[32]\tvalid_0's binary_logloss: -1.02431\tvalid_0's error: 0.0442679\tvalid_0's accuracy: 0.955732\n",
      "[33]\tvalid_0's binary_logloss: -1.33584\tvalid_0's error: 0.0397276\tvalid_0's accuracy: 0.960272\n",
      "[34]\tvalid_0's binary_logloss: -1.15221\tvalid_0's error: 0.045403\tvalid_0's accuracy: 0.954597\n",
      "[35]\tvalid_0's binary_logloss: -1.35538\tvalid_0's error: 0.0419977\tvalid_0's accuracy: 0.958002\n",
      "[36]\tvalid_0's binary_logloss: -1.43426\tvalid_0's error: 0.0408627\tvalid_0's accuracy: 0.959137\n",
      "[37]\tvalid_0's binary_logloss: -0.28645\tvalid_0's error: 0.0692395\tvalid_0's accuracy: 0.93076\n",
      "[38]\tvalid_0's binary_logloss: 0.176808\tvalid_0's error: 0.0862656\tvalid_0's accuracy: 0.913734\n",
      "[39]\tvalid_0's binary_logloss: -0.317702\tvalid_0's error: 0.0726447\tvalid_0's accuracy: 0.927355\n",
      "[40]\tvalid_0's binary_logloss: -0.442357\tvalid_0's error: 0.0737798\tvalid_0's accuracy: 0.92622\n",
      "[41]\tvalid_0's binary_logloss: -0.603903\tvalid_0's error: 0.0703746\tvalid_0's accuracy: 0.929625\n",
      "[42]\tvalid_0's binary_logloss: -0.563898\tvalid_0's error: 0.0737798\tvalid_0's accuracy: 0.92622\n",
      "[43]\tvalid_0's binary_logloss: -0.434499\tvalid_0's error: 0.0760499\tvalid_0's accuracy: 0.92395\n",
      "[44]\tvalid_0's binary_logloss: -0.0515926\tvalid_0's error: 0.0874007\tvalid_0's accuracy: 0.912599\n",
      "[45]\tvalid_0's binary_logloss: 0.62291\tvalid_0's error: 0.115778\tvalid_0's accuracy: 0.884222\n",
      "[46]\tvalid_0's binary_logloss: 2.01134\tvalid_0's error: 0.148695\tvalid_0's accuracy: 0.851305\n",
      "[47]\tvalid_0's binary_logloss: 1.13626\tvalid_0's error: 0.128263\tvalid_0's accuracy: 0.871737\n",
      "[48]\tvalid_0's binary_logloss: 0.577602\tvalid_0's error: 0.124858\tvalid_0's accuracy: 0.875142\n",
      "[49]\tvalid_0's binary_logloss: 0.955112\tvalid_0's error: 0.131669\tvalid_0's accuracy: 0.868331\n",
      "[50]\tvalid_0's binary_logloss: 1.11095\tvalid_0's error: 0.136209\tvalid_0's accuracy: 0.863791\n",
      "[51]\tvalid_0's binary_logloss: 1.76833\tvalid_0's error: 0.1521\tvalid_0's accuracy: 0.8479\n",
      "[52]\tvalid_0's binary_logloss: 1.58044\tvalid_0's error: 0.150965\tvalid_0's accuracy: 0.849035\n",
      "[53]\tvalid_0's binary_logloss: 2.16094\tvalid_0's error: 0.169126\tvalid_0's accuracy: 0.830874\n",
      "[54]\tvalid_0's binary_logloss: 3.11987\tvalid_0's error: 0.195233\tvalid_0's accuracy: 0.804767\n",
      "[55]\tvalid_0's binary_logloss: 2.61904\tvalid_0's error: 0.186152\tvalid_0's accuracy: 0.813848\n",
      "[56]\tvalid_0's binary_logloss: 1.96793\tvalid_0's error: 0.171396\tvalid_0's accuracy: 0.828604\n",
      "[57]\tvalid_0's binary_logloss: 2.73811\tvalid_0's error: 0.198638\tvalid_0's accuracy: 0.801362\n",
      "[58]\tvalid_0's binary_logloss: 2.16021\tvalid_0's error: 0.187287\tvalid_0's accuracy: 0.812713\n",
      "[59]\tvalid_0's binary_logloss: 1.83987\tvalid_0's error: 0.179342\tvalid_0's accuracy: 0.820658\n",
      "[60]\tvalid_0's binary_logloss: 1.67051\tvalid_0's error: 0.178207\tvalid_0's accuracy: 0.821793\n",
      "[61]\tvalid_0's binary_logloss: 1.51001\tvalid_0's error: 0.177072\tvalid_0's accuracy: 0.822928\n",
      "[62]\tvalid_0's binary_logloss: 2.89428\tvalid_0's error: 0.220204\tvalid_0's accuracy: 0.779796\n",
      "[63]\tvalid_0's binary_logloss: 3.39992\tvalid_0's error: 0.231555\tvalid_0's accuracy: 0.768445\n",
      "[64]\tvalid_0's binary_logloss: 3.64674\tvalid_0's error: 0.240636\tvalid_0's accuracy: 0.759364\n",
      "[65]\tvalid_0's binary_logloss: 2.45963\tvalid_0's error: 0.22361\tvalid_0's accuracy: 0.77639\n",
      "[66]\tvalid_0's binary_logloss: 2.71651\tvalid_0's error: 0.23042\tvalid_0's accuracy: 0.76958\n",
      "[67]\tvalid_0's binary_logloss: 4.01924\tvalid_0's error: 0.267877\tvalid_0's accuracy: 0.732123\n",
      "[68]\tvalid_0's binary_logloss: 4.57525\tvalid_0's error: 0.283768\tvalid_0's accuracy: 0.716232\n",
      "[69]\tvalid_0's binary_logloss: 4.36031\tvalid_0's error: 0.288309\tvalid_0's accuracy: 0.711691\n",
      "[70]\tvalid_0's binary_logloss: 5.37169\tvalid_0's error: 0.314415\tvalid_0's accuracy: 0.685585\n",
      "[71]\tvalid_0's binary_logloss: 4.11333\tvalid_0's error: 0.287174\tvalid_0's accuracy: 0.712826\n",
      "[72]\tvalid_0's binary_logloss: 7.96819\tvalid_0's error: 0.38933\tvalid_0's accuracy: 0.61067\n",
      "[73]\tvalid_0's binary_logloss: -0.0797287\tvalid_0's error: 0.222474\tvalid_0's accuracy: 0.777526\n",
      "[74]\tvalid_0's binary_logloss: -0.680741\tvalid_0's error: 0.211124\tvalid_0's accuracy: 0.788876\n",
      "[75]\tvalid_0's binary_logloss: -0.142345\tvalid_0's error: 0.227015\tvalid_0's accuracy: 0.772985\n",
      "[76]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[77]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[78]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[79]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[80]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[81]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[82]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[83]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[84]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[85]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[86]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[87]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[88]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[89]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[90]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[91]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[92]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[93]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[94]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[95]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[96]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[97]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[98]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[99]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n",
      "[100]\tvalid_0's binary_logloss: -0.792212\tvalid_0's error: 0.214529\tvalid_0's accuracy: 0.785471\n"
     ]
    }
   ],
   "source": [
    "def loglikelihood(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    preds = 1. / (1. + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1. - preds)\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, eval_result: float, is_higher_better: bool\n",
    "# binary error\n",
    "def binary_error(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'error', np.mean(labels != (preds > 0.5)), False\n",
    "\n",
    "\n",
    "print('Finished 40 - 50 rounds with self-defined objective function and eval metric...')\n",
    "\n",
    "\n",
    "# another self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, eval_result: float, is_higher_better: bool\n",
    "# accuracy\n",
    "def accuracy(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'accuracy', np.mean(labels == (preds > 0.5)), True\n",
    "\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                fobj=loglikelihood,\n",
    "                feval=lambda preds, train_data: [binary_error(preds, train_data),\n",
    "                                                 accuracy(preds, train_data)],\n",
    "                valid_sets=lgb_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7854710556186152"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gbm.predict(X, num_iteration=gbm.best_iteration) > 0.5\n",
    "accuracy_score(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objetive = binary   => regresson on (0,1) => 1.1 => sigmoid(1.1) (this is y_pred) => calc error => finish 1 round, return  y_pred=sigmoid(1.1) \n",
    "\n",
    "objetive = log_loss_customer_func   => regresson on (0,1) => 1.1 (this is y_pred) => sigmoid(1.1) => calc error => finish 1 round,  return  y_pred=1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hessian ?\n",
    "how to find best split\n",
    "how to minimize error after know index for best split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
